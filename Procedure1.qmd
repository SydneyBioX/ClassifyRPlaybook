# Procedure 1

## Intro

text

## Next thing

more text

```{r message = FALSE}
library(ClassifyR)
library(sparsediscrim)
library(tidyverse)
library(SingleCellExperiment)
library(openxlsx)
library(pROC)
library(ggplot2)
library(reshape2)
```


## Final Procedure using SCM Classifier with 5% of features selected from t-test
```{r warning = FALSE, message = FALSE}
set.seed(1)
clinical = read.xlsx("data/procedure1/clinical.xlsx")
clusters <- readRDS("data/procedure1/cluster_result_ER_and_PR_onlyER+PR+.rds")
p <- readRDS("data/procedure1/pseudobulk_overall_sum.rds")
p <- p[rownames(p) %in% clusters$sample_id, ]
p_cell <- readRDS("data/procedure1/pseudobulk_celltype_sum.rds")
p_cell <- p_cell[rownames(p_cell) %in% clusters$sample_id, ]
data = list("pseudo_bulk_overall" = p, "pseudo_bulk_cell" = p_cell)
nFeatures = list(pseudo_bulk_overall = 0.05*ncol(p), pseudo_bulk_cell = 0.05*ncol(p_cell))
outcome = as.factor(clusters$cluster)

classifyr_result3 <- crossValidate(data, outcome = outcome, classifier = "SVM", nFeatures = nFeatures, nFolds = 5, nRepeats = 100, nCores = 5)
performancePlot(classifyr_result3)
samplesMetricMap(classifyr_result3)

classifyr_result3 <- sapply(classifyr_result3, function(results) {
  calcCVperformance(results, performanceType = "Sample Accuracy")
}) # loop to calculate sample accuracy
accuracyMatrix <- sapply(classifyr_result3, function(result) performance(result)[["Sample Accuracy"]])
plot(accuracyMatrix) #scatterplot of sample accuracies for both datasets
```

# Classifier Selection Plot

```{r}
# classifier must exactly match these options: randomForest, DLDA, kNN, GLM, ridgeGLM, elasticNetGLM, LASSOGLM, SVM, NSC, naiveBayes, mixturesNormals, CoxPH, CoxNet, randomSurvivalForest, XGB

# Perform cross-validation for each classifier
classifyr_result <- crossValidate(
    p,  
    outcome = outcome,  
    selectionMethod = "auto", 
    classifier = c("SVM", "kNN", "randomForest", 
               "naiveBayes", "XGB"), # Use the current classifier in the loop. but result will be a list of objects so it can't be put into calcCVperformance
    nFeatures = 0.05 * nrow(p), 
    nFolds = 5,              
    nRepeats = 5,            
    nCores = 5,
    characteristicsLabel = "overall_pseudobulking"
)


classifyr_result2 <- crossValidate(
    p_cell,  
    outcome = outcome,  
    selectionMethod = "auto", 
    classifier =  c("SVM", "kNN", "randomForest", 
               "naiveBayes", "XGB"), # Use the current classifier in the loop. but result will be a list of objects so it can't be put into calcCVperformance
    nFeatures = 0.05 * nrow(p_cell), 
    nFolds = 5,              
    nRepeats = 5,            
    nCores = 5,
    characteristicsLabel = "cell_specific_pseudobulking"
  )

results_both = append(classifyr_result, classifyr_result2)

results_both <- lapply(results_both, function(results) {
  calcCVperformance(results, performanceType = "Balanced Accuracy")
})

performancePlot(results_both, characteristicsList = list(x = "auto", fillColour = "characteristicsLabel")) + theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) #performancePlot is essentially ggplot, so just add one more things
```
