[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ClassifyR PlayBook",
    "section": "",
    "text": "1 Overview",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "ClassifyR PlayBook",
    "section": "1.1 Welcome!",
    "text": "1.1 Welcome!\ntext",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#ummm",
    "href": "index.html#ummm",
    "title": "ClassifyR PlayBook",
    "section": "1.2 ummm",
    "text": "1.2 ummm\nmore text",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "Procedure1.html",
    "href": "Procedure1.html",
    "title": "2  Procedure 1",
    "section": "",
    "text": "2.1 Intro\nProcedure 1 aims to compare the classification sample accuracy in bulked and pseudobulked data using an SVM classifier. Sample accuracy calcualtes the proportion of correct predicted classifications over n repeats. For example, if 70 out of 100 repeats accurately classify an individual, their sample accuracy is 0.70.\nFor this analysis, a single-cell transcriptomics dataset for 54 oestrogen receptor positive (ER+)/progesterone receptor positive (PR+) breast cancer patients is used. There are 280 genes and 6 cell types. The classification outcomes are ‘cluster 1’ and ‘cluster 2’, found by unsupervised machine learning. Cluster 1 corresponds to patients with higher expression of LPL, CAVIN2, and TIMP4 in macrophage cells, and ADIPOQ in stromal cells, associated with better survival. Cluster 2 is the opposite, associated with poorer survival. More details on the clusters can be found at https://www.biorxiv.org/content/10.1101/2024.07.02.601790v1.full.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#next-thing",
    "href": "Procedure1.html#next-thing",
    "title": "2  Procedure 1",
    "section": "2.2 Next thing",
    "text": "2.2 Next thing\nmore text\n\nlibrary(ClassifyR)\nlibrary(sparsediscrim)\nlibrary(tidyverse)\nlibrary(SingleCellExperiment)\nlibrary(openxlsx)\nlibrary(pROC)\nlibrary(ggplot2)\nlibrary(reshape2)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1</span>"
    ]
  },
  {
    "objectID": "Procedure2.html",
    "href": "Procedure2.html",
    "title": "3  Procedure 2",
    "section": "",
    "text": "3.1 Intro\ntext",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procedure 2</span>"
    ]
  },
  {
    "objectID": "Procedure2.html#next-thing",
    "href": "Procedure2.html#next-thing",
    "title": "3  Procedure 2",
    "section": "3.2 Next thing",
    "text": "3.2 Next thing\nmore text",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procedure 2</span>"
    ]
  },
  {
    "objectID": "Procedure3.html",
    "href": "Procedure3.html",
    "title": "4  Procedure 3",
    "section": "",
    "text": "4.1 Intro\ntext",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Procedure 3</span>"
    ]
  },
  {
    "objectID": "Procedure3.html#next-thing",
    "href": "Procedure3.html#next-thing",
    "title": "4  Procedure 3",
    "section": "4.2 Next thing",
    "text": "4.2 Next thing\nmore text\n\nset.seed(1)\nsuppressPackageStartupMessages(library(ClassifyR))\nmae &lt;- readRDS(\"data/procedure3/MultiAssayExperiment.rds\")\npp &lt;- precisionPathwaysTrain(mae, \"Outcome\")\n\nWarning in .local(measurements, class, ...): No 'useFeatures' named list element for clincal data is specified. Clinical data often has\nlots of uninformative variables. Please consider specifying useful features.\n\npp &lt;- calcCostsAndPerformance(pp, setNames(c(30, 100, 50), c(\"Clinical\", \"RNA_pair\", \"miRNA_pair\")))\nsummary(pp)\n\n                       Pathway Balanced Accuracy Total Cost Score\n1            clinical-RNA_pair              0.76       1800  1.25\n2 clinical-miRNA_pair-RNA_pair              0.76       1400  1.75\n\nbubblePlot(pp)\n\nWarning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\nℹ The deprecated feature was likely used in the ClassifyR package.\n  Please report the issue to the authors.\n\n\n\n\n\n\n\n\nstrataPlot(pp, \"clinical-RNA_pair\")\n\n\n\n\n\n\n\nflowchart(pp, \"clinical-RNA_pair\")\n\n\n\n\npredictions &lt;- precisionPathwaysPredict(pp, mae, \"Outcome\")\npredictions$pathways\n\n$`clinical-RNA_pair`\n$`clinical-RNA_pair`$pathway\n[1] \"clinical-RNA_pair\"\n\n$`clinical-RNA_pair`$individuals\nDataFrame with 62 rows and 4 columns\n        Tier    Sample ID Predicted  Accuracy\n    &lt;factor&gt;  &lt;character&gt;  &lt;factor&gt; &lt;numeric&gt;\n1   clinical TCGA-BF-A1PX      Poor      1.00\n2   clinical TCGA-D3-A1Q6      Poor      0.00\n3   clinical TCGA-D3-A1QB      Good      1.00\n4   clinical TCGA-D3-A2JA      Good      0.95\n5   clinical TCGA-D3-A2JC      Good      1.00\n...      ...          ...       ...       ...\n58  RNA_pair TCGA-D9-A6EC      Poor      0.40\n59  RNA_pair TCGA-EE-A3JB      Good      0.50\n60  RNA_pair TCGA-EE-A3JE      Good      0.90\n61  RNA_pair TCGA-EE-A29A      Good      0.75\n62  RNA_pair TCGA-ER-A2NG      Good      0.85\n\n$`clinical-RNA_pair`$tiers\nDataFrame with 2 rows and 2 columns\n         Tier Balanced Accuracy\n  &lt;character&gt;         &lt;numeric&gt;\n1    clinical          0.757576\n2    RNA_pair          0.687500\n\n\n$`clinical-miRNA_pair-RNA_pair`\n$`clinical-miRNA_pair-RNA_pair`$pathway\n[1] \"clinical-miRNA_pair-RNA_pair\"\n\n$`clinical-miRNA_pair-RNA_pair`$individuals\nDataFrame with 62 rows and 4 columns\n        Tier    Sample ID Predicted  Accuracy\n    &lt;factor&gt;  &lt;character&gt;  &lt;factor&gt; &lt;numeric&gt;\n1   clinical TCGA-BF-A1PX      Poor      1.00\n2   clinical TCGA-D3-A1Q6      Poor      0.00\n3   clinical TCGA-D3-A1QB      Good      1.00\n4   clinical TCGA-D3-A2JA      Good      0.95\n5   clinical TCGA-D3-A2JC      Good      1.00\n...      ...          ...       ...       ...\n58  RNA_pair TCGA-EB-A3Y7      Poor      0.85\n59  RNA_pair TCGA-D3-A8GP      Poor      0.35\n60  RNA_pair TCGA-D9-A6EC      Poor      0.40\n61  RNA_pair TCGA-EE-A3JB      Good      0.50\n62  RNA_pair TCGA-ER-A2NG      Good      0.85\n\n$`clinical-miRNA_pair-RNA_pair`$tiers\nDataFrame with 3 rows and 2 columns\n         Tier Balanced Accuracy\n  &lt;character&gt;         &lt;numeric&gt;\n1    clinical          0.757576\n2  miRNA_pair          1.000000\n3    RNA_pair          0.625000",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Procedure 3</span>"
    ]
  },
  {
    "objectID": "Procedure4.html",
    "href": "Procedure4.html",
    "title": "5  Procedure 4",
    "section": "",
    "text": "5.1 Intro\ntext",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Procedure 4</span>"
    ]
  },
  {
    "objectID": "Procedure4.html#next-thing",
    "href": "Procedure4.html#next-thing",
    "title": "5  Procedure 4",
    "section": "5.2 Next thing",
    "text": "5.2 Next thing\nmore text",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Procedure 4</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#simplified",
    "href": "Procedure1.html#simplified",
    "title": "2  Procedure 1",
    "section": "2.3 Simplified",
    "text": "2.3 Simplified\n\nset.seed(1)\nclinical = read.xlsx(\"clinical.xlsx\")\nclusters &lt;- readRDS(\"cluster_result_ER_and_PR_onlyER+PR+.rds\")\np &lt;- readRDS(\"pseudobulk_overall_sum.rds\") \np &lt;-p[rownames(p) %in% clusters$sample_id, ]\np_cell &lt;- readRDS(\"pseudobulk_celltype_sum.rds\")\np_cell &lt;-p_cell[rownames(p_cell) %in% clusters$sample_id, ]\noutcome = clusters$cluster\n\nclassifyr_result &lt;- crossValidate(p, outcome = outcome, selectionMethod = \"auto\", classifier = \"SVM\", nFeatures = 0.05 * nrow(p), nFolds = 5, nRepeats = 5, nCores = 5, characteristicsLabel = \"overall_pseudobulking\")\nclassifyr_result2 &lt;- crossValidate(p_cell, outcome = outcome, selectionMethod = \"auto\", classifier = \"SVM\", nFeatures = 0.05 * nrow(p_cell), nFolds = 5, nRepeats = 5, nCores = 5, characteristicsLabel = \"cell_specific_pseudobulking\")\nresults_both = append(classifyr_result, classifyr_result2)\nresults_both &lt;- lapply(results_both, function(results) {\n  calcCVperformance(results, performanceType = \"Balanced Accuracy\")\n})\nperformancePlot(results_both, characteristicsList = list(x = \"auto\", fillColour = \"characteristicsLabel\")) + theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) #performancePlot is essentially ggplot, so just add one more things\n\n\n\n\n\n\n\n\n\n# classifier must exactly match these options: randomForest, DLDA, kNN, GLM, ridgeGLM, elasticNetGLM, LASSOGLM, SVM, NSC, naiveBayes, mixturesNormals, CoxPH, CoxNet, randomSurvivalForest, XGB\n\n# Perform cross-validation for each classifier\nclassifyr_result &lt;- crossValidate(\n    p,  \n    outcome = outcome,  \n    selectionMethod = \"auto\", \n    classifier = c(\"SVM\", \"kNN\", \"randomForest\", \n               \"naiveBayes\", \"XGB\"), # Use the current classifier in the loop. but result will be a list of objects so it can't be put into calcCVperformance\n    nFeatures = 0.05 * nrow(p), \n    nFolds = 5,              \n    nRepeats = 5,            \n    nCores = 5,\n    characteristicsLabel = \"overall_pseudobulking\"\n)\n\n\nclassifyr_result2 &lt;- crossValidate(\n    p_cell,  \n    outcome = outcome,  \n    selectionMethod = \"auto\", \n    classifier = c(\"SVM\"), # Use the current classifier in the loop. but result will be a list of objects so it can't be put into calcCVperformance\n    nFeatures = 0.05 * nrow(p_cell), \n    nFolds = 5,              \n    nRepeats = 5,            \n    nCores = 5,\n    characteristicsLabel = \"cell_specific_pseudobulking\"\n  )\n\nresults_both = append(classifyr_result, classifyr_result2)\n\nresults_both &lt;- lapply(results_both, function(results) {\n  calcCVperformance(results, performanceType = \"Balanced Accuracy\")\n})\n\nperformancePlot(results_both, characteristicsList = list(x = \"auto\", fillColour = \"characteristicsLabel\")) + theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) #performancePlot is essentially ggplot, so just add one more things",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#overall-pseudobulked-data",
    "href": "Procedure1.html#overall-pseudobulked-data",
    "title": "2  Procedure 1",
    "section": "3.2 Overall Pseudobulked Data",
    "text": "3.2 Overall Pseudobulked Data\n\nclinical = read.xlsx(\"clinical.xlsx\")\noutcome = substring(clinical$OS_STATUS,1,1)\n\np &lt;- readRDS(\"pseudobulk_overall_sum.rds\")\np_filtered &lt;- p[, colSums(p != 0) &gt; 0, drop = FALSE]\n\np_values &lt;- sapply(colnames(p_filtered), function(feature) {\n  t.test(p_filtered[[feature]] ~ outcome, na.action = na.omit)$p.value\n})\nselected_features &lt;- colnames(p_filtered)[p_values &lt; 0.05]\ncat(\"The selected features by cell-specific pseudobulking using an fdr of 0.05 are:\\n\", \n    paste(selected_features, collapse = \", \"), \"\\n\")\n\nThe selected features by cell-specific pseudobulking using an fdr of 0.05 are:\n ADGRE5, AIF1, FGL2, FOXC2, GLIPR1, ITM2C, LDHB, MMP12, S100A4, SMAP2, SSTR2, TCEAL7, TOMM7 \n\nomics_selected &lt;- p_filtered[,selected_features]  # Subset omics data\nnFeatures &lt;- list(omics = 1:length(selected_features))\n\nclassifyr_result &lt;- crossValidate(\n  list(omics = omics_selected),  # Only use omics data\n  outcome = outcome,  # Use the outcome column\n  extraParams = list(prepare = list(useFeatures = list(omics = selected_features))),\n  nFeatures = nFeatures,\n  nFolds = 5,       # 5-fold cross-validation\n  nRepeats = 5,     # 5 repeats\n  nCores = 5        # Parallel processing with 5 cores\n)\nsaveRDS(classifyr_result, file = \"classifyr_result.rds\")\n\nclassifyr_result_forest &lt;- crossValidate(\n  list(omics = omics_selected),  # Only use omics data\n  outcome = outcome,  # Use the outcome column\n  extraParams = list(prepare = list(useFeatures = list(omics = selected_features))),\n  nFeatures = nFeatures,\n  classifier = \"randomForest\",\n  nFolds = 5,       # 5-fold cross-validation\n  nRepeats = 5,     # 5 repeats\n  nCores = 5        # Parallel processing with 5 cores\n)\n\n\n3.2.1 Performance comparison between Cox proportional hazards & random survival forest\n\n# Extract predictions\npredictions &lt;- predictions(classifyr_result)\nnamed_outcomes &lt;- setNames(as.list(outcome),clinical$patientId)\n# Actual outcomes\npredictions$actual &lt;- named_outcomes\npredictions$actual &lt;- unlist(predictions$actual)\n# Generate the confusion matrix\nconfusion_matrix &lt;- table(Predicted = predictions$class, Actual = predictions$actual)\nprint(confusion_matrix)\n\n         Actual\nPredicted   0   1\n        0 393  45\n        1  22   0\n\n#Performance Metrics\nTP &lt;- diag(confusion_matrix)\nFN &lt;- rowSums(confusion_matrix) - TP\nFP &lt;- colSums(confusion_matrix) - TP\nTN &lt;- sum(confusion_matrix) - (TP + FP + FN)\nsensitivity &lt;- TP / (TP + FN) # Recall or Sensitivity\nspecificity &lt;- TN / (TN + FP) # Specificity\nprecision &lt;- TP / (TP + FP)   # Precision\naccuracy &lt;- sum(TP) / sum(confusion_matrix)\nf1_score &lt;- 2 * (precision * sensitivity) / (precision + sensitivity)\ncat(\"Metrics for predictions from overall pseudobulking:\\n\")\n\nMetrics for predictions from overall pseudobulking:\n\ncat(\"Accuracy:\", accuracy, \"\\n\")\n\nAccuracy: 0.8543478 \n\ncat(\"Sensitivity (Recall) per class:\", sensitivity, \"\\n\")\n\nSensitivity (Recall) per class: 0.8972603 0 \n\ncat(\"Specificity per class:\", specificity, \"\\n\")\n\nSpecificity per class: 0 0.8972603 \n\ncat(\"Precision per class:\", precision, \"\\n\")\n\nPrecision per class: 0.946988 0 \n\ncat(\"F1 Score per class:\", f1_score, \"\\n\")\n\nF1 Score per class: 0.9214537 NaN \n\n#Confusion_matrix package to calculate everything: \n\n# Extract predictions\npredictions_forest &lt;- predictions(classifyr_result_forest)\npredictions_forest$actual &lt;- named_outcomes #actual outcome\npredictions_forest$actual &lt;- unlist(predictions_forest$actual)\n# Generate the confusion matrix\nconfusion_matrix_forest &lt;- table(Predicted = predictions_forest$class, Actual = predictions_forest$actual)\n# View the confusion matrix\nprint(confusion_matrix_forest)\n\n         Actual\nPredicted   0   1\n        0 395  45\n        1  20   0\n\nTP &lt;- diag(confusion_matrix_forest)\nFN &lt;- rowSums(confusion_matrix_forest) - TP\nFP &lt;- colSums(confusion_matrix_forest) - TP\nTN &lt;- sum(confusion_matrix_forest) - (TP + FP + FN)\n# Performance Metrics\nsensitivity &lt;- TP / (TP + FN) # Recall or Sensitivity\nspecificity &lt;- TN / (TN + FP) # Specificity\nprecision &lt;- TP / (TP + FP)   # Precision\naccuracy &lt;- sum(TP) / sum(confusion_matrix_forest)\nf1_score &lt;- 2 * (precision * sensitivity) / (precision + sensitivity)\n\ncat(\"Metrics for predictions from overall pseudobulking using random forest:\\n\")\n\nMetrics for predictions from overall pseudobulking using random forest:\n\ncat(\"Accuracy:\", accuracy, \"\\n\")\n\nAccuracy: 0.8586957 \n\ncat(\"Sensitivity (Recall) per class:\", sensitivity, \"\\n\")\n\nSensitivity (Recall) per class: 0.8977273 0 \n\ncat(\"Specificity per class:\", specificity, \"\\n\")\n\nSpecificity per class: 0 0.8977273 \n\ncat(\"Precision per class:\", precision, \"\\n\")\n\nPrecision per class: 0.9518072 0 \n\ncat(\"F1 Score per class:\", f1_score, \"\\n\")\n\nF1 Score per class: 0.9239766 NaN",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#cell-specific-pseudobulked-data",
    "href": "Procedure1.html#cell-specific-pseudobulked-data",
    "title": "2  Procedure 1",
    "section": "3.3 Cell-specific Pseudobulked Data",
    "text": "3.3 Cell-specific Pseudobulked Data\n\np_cell &lt;- readRDS(\"pseudobulk_celltype_sum.rds\")\np_cell_filtered &lt;- p_cell[, colSums(p_cell != 0) &gt; 0, drop = FALSE]\n\np_values_cell &lt;- sapply(colnames(p_cell_filtered), function(feature) {\n  t.test(p_cell_filtered[[feature]] ~ outcome, na.action = na.omit)$p.value\n})\n\nselected_cell_features &lt;- colnames(p_cell_filtered)[p_values_cell &lt; 0.05]\ncat(\"The selected features by cell-specific pseudobulking using an fdr of 0.05 are:\\n\", \n    paste(selected_cell_features, collapse = \", \"), \"\\n\")\n\nThe selected features by cell-specific pseudobulking using an fdr of 0.05 are:\n Stromal__SSTR2, Malignant__C5orf46, Malignant__CLEC9A, Malignant__MMP12, Malignant__TCEAL7, Malignant__TCL1A, T__SSTR2, T__TCEAL7, Macrophage__CLEC9A, Macrophage__FOXC2, Macrophage__MMP12, Macrophage__SSTR2, Macrophage__TCEAL7, Myoepi__FOXC2, DC_Mast__ADIPOQ, DC_Mast__C5orf46, DC_Mast__SCGB2A1, DC_Mast__SSTR2, DC_Mast__TCEAL7 \n\nomics_selected_cell &lt;- p_cell_filtered[,selected_cell_features]  # Subset omics data\nnFeatures_cell &lt;- list(omics = 1:length(selected_cell_features))\n\nclassifyr_result_cell &lt;- crossValidate(\n  list(omics = omics_selected_cell),  \n  outcome = outcome,  # Use the outcome column\n  extraParams = list(prepare = list(useFeatures = list(omics = selected_cell_features))),\n  nFeatures = nFeatures_cell,\n  nFolds = 5,       # 5-fold cross-validation\n  nRepeats = 5,     # 5 repeats\n  nCores = 5        # Parallel processing with 5 cores\n)\nsaveRDS(classifyr_result_cell, file = \"classifyr_result_cell.rds\")\n\nclassifyr_result_cell_forest &lt;- crossValidate(\n  list(omics = omics_selected_cell),  # Only use omics data\n  outcome = outcome,  # Use the outcome column\n  extraParams = list(prepare = list(useFeatures = list(omics = selected_cell_features))),\n  nFeatures = nFeatures_cell,\n  classifier = \"randomForest\",\n  nFolds = 5,       # 5-fold cross-validation\n  nRepeats = 5,     # 5 repeats\n  nCores = 5        # Parallel processing with 5 cores\n)\n\n\n3.3.1 Performance comparison between Cox proportional hazards & random survival forest\n\n# Extract predictions\npredictions_cell &lt;- predictions(classifyr_result_cell)\nnamed_outcomes &lt;- setNames(as.list(outcome),clinical$patientId)\n# Actual Outcomes\npredictions_cell$actual &lt;- named_outcomes\npredictions_cell$actual &lt;- unlist(predictions_cell$actual)\n# Generate the confusion matrix\nconfusion_matrix_cell &lt;- table(Predicted = predictions_cell$class, Actual = predictions_cell$actual)\nprint(confusion_matrix_cell)\n\n         Actual\nPredicted   0   1\n        0 403  43\n        1  12   2\n\nTP &lt;- diag(confusion_matrix_cell)\nFN &lt;- rowSums(confusion_matrix_cell) - TP\nFP &lt;- colSums(confusion_matrix_cell) - TP\nTN &lt;- sum(confusion_matrix_cell) - (TP + FP + FN)\n# Performance Metrics\nsensitivity &lt;- TP / (TP + FN) # Recall or Sensitivity\nspecificity &lt;- TN / (TN + FP) # Specificity\nprecision &lt;- TP / (TP + FP)   # Precision'accuracy &lt;- sum(TP) / sum(confusion_matrix_cell_forest)\naccuracy &lt;- sum(TP) / sum(confusion_matrix_cell)\nf1_score &lt;- 2 * (precision * sensitivity) / (precision + sensitivity)\ncat(\"Metrics for predictions from cell-specific pseudobulking:\\n\")\n\nMetrics for predictions from cell-specific pseudobulking:\n\ncat(\"Accuracy:\", accuracy, \"\\n\")\n\nAccuracy: 0.8804348 \n\ncat(\"Sensitivity (Recall) per class:\", sensitivity, \"\\n\")\n\nSensitivity (Recall) per class: 0.9035874 0.1428571 \n\ncat(\"Specificity per class:\", specificity, \"\\n\")\n\nSpecificity per class: 0.1428571 0.9035874 \n\ncat(\"Precision per class:\", precision, \"\\n\")\n\nPrecision per class: 0.9710843 0.04444444 \n\ncat(\"F1 Score per class:\", f1_score, \"\\n\")\n\nF1 Score per class: 0.9361208 0.06779661 \n\n# Extract predictions\npredictions_cell_forest &lt;- predictions(classifyr_result_cell_forest)\npredictions_cell_forest$actual &lt;- named_outcomes #actual outcome\npredictions_cell_forest$actual &lt;- unlist(predictions_cell_forest$actual)\n# Generate the confusion matrix\nconfusion_matrix_cell_forest &lt;- table(Predicted = predictions_cell_forest$class, Actual = predictions_cell_forest$actual)\n# View the confusion matrix\nprint(confusion_matrix_cell_forest)\n\n         Actual\nPredicted   0   1\n        0 399  45\n        1  16   0\n\n# Total True Positives (TP), True Negatives (TN), False Positives (FP), False Negatives (FN)\nTP &lt;- diag(confusion_matrix_cell_forest)\nFN &lt;- rowSums(confusion_matrix_cell_forest) - TP\nFP &lt;- colSums(confusion_matrix_cell_forest) - TP\nTN &lt;- sum(confusion_matrix_cell_forest) - (TP + FP + FN)\n\n# Calculating metrics for each class\nsensitivity &lt;- TP / (TP + FN) # Recall or Sensitivity\nspecificity &lt;- TN / (TN + FP) # Specificity\nprecision &lt;- TP / (TP + FP)   # Precision\naccuracy &lt;- sum(TP) / sum(confusion_matrix_cell_forest)\nf1_score &lt;- 2 * (precision * sensitivity) / (precision + sensitivity)\n\ncat(\"Metrics for predictions from cell-specific pseudobulking using random forest:\\n\")\n\nMetrics for predictions from cell-specific pseudobulking using random forest:\n\ncat(\"Accuracy:\", accuracy, \"\\n\")\n\nAccuracy: 0.8673913 \n\ncat(\"Sensitivity (Recall) per class:\", sensitivity, \"\\n\")\n\nSensitivity (Recall) per class: 0.8986486 0 \n\ncat(\"Specificity per class:\", specificity, \"\\n\")\n\nSpecificity per class: 0 0.8986486 \n\ncat(\"Precision per class:\", precision, \"\\n\")\n\nPrecision per class: 0.9614458 0 \n\ncat(\"F1 Score per class:\", f1_score, \"\\n\")\n\nF1 Score per class: 0.9289872 NaN",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#final-procedure-using-scm-classifier-with-5-of-features-selected-from-t-test",
    "href": "Procedure1.html#final-procedure-using-scm-classifier-with-5-of-features-selected-from-t-test",
    "title": "2  Procedure 1",
    "section": "2.3 Final Procedure using SCM Classifier with 5% of features selected from t-test",
    "text": "2.3 Final Procedure using SCM Classifier with 5% of features selected from t-test\n\nset.seed(1)\nclinical = read.xlsx(\"data/procedure1/clinical.xlsx\")\nclusters &lt;- readRDS(\"data/procedure1/cluster_result_ER_and_PR_onlyER+PR+.rds\")\np &lt;- readRDS(\"data/procedure1/pseudobulk_overall_sum.rds\")\np &lt;- p[rownames(p) %in% clusters$sample_id, ]\np_cell &lt;- readRDS(\"data/procedure1/pseudobulk_celltype_sum.rds\")\np_cell &lt;- p_cell[rownames(p_cell) %in% clusters$sample_id, ]\ndata = list(\"pseudo_bulk_overall\" = p, \"pseudo_bulk_cell\" = p_cell)\nnFeatures = list(pseudo_bulk_overall = 0.05*ncol(p), pseudo_bulk_cell = 0.05*ncol(p_cell))\noutcome = as.factor(clusters$cluster)\n\nclassifyr_result3 &lt;- crossValidate(data, outcome = outcome, classifier = \"SVM\", nFeatures = nFeatures, nFolds = 5, nRepeats = 100, nCores = 5)\nperformancePlot(classifyr_result3)\nsamplesMetricMap(classifyr_result3)\n\n\n\n\n\n\n\n\nTableGrob (2 x 1) \"arrange\": 2 grobs\n  z     cells    name                grob\n1 1 (2-2,1-1) arrange      gtable[layout]\n2 2 (1-1,1-1) arrange text[GRID.text.274]\n\nclassifyr_result3 &lt;- sapply(classifyr_result3, function(results) {\n  calcCVperformance(results, performanceType = \"Sample Accuracy\")\n}) # loop to calculate sample accuracy\naccuracyMatrix &lt;- sapply(classifyr_result3, function(result) performance(result)[[\"Sample Accuracy\"]])\nplot(accuracyMatrix) #scatterplot of sample accuracies for both datasets",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#everything-below-is-verbose-non-classifyr-code-left-in-for-comparison",
    "href": "Procedure1.html#everything-below-is-verbose-non-classifyr-code-left-in-for-comparison",
    "title": "2  Procedure 1",
    "section": "3.1 Everything below is verbose non-ClassifyR Code (Left in for comparison)",
    "text": "3.1 Everything below is verbose non-ClassifyR Code (Left in for comparison)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#set-up-the-environment-and-data-objects",
    "href": "Procedure1.html#set-up-the-environment-and-data-objects",
    "title": "2  Procedure 1",
    "section": "2.2 Set up the environment and data objects",
    "text": "2.2 Set up the environment and data objects\n1. Load the R packages into the R environment:\nTiming ~ 6.5s\n\nlibrary(ClassifyR)\nlibrary(openxlsx)\n\n2. Import datasets\nTiming ~ 0.15s\n\np &lt;- readRDS(\"data/procedure1/pseudobulk_overall_sum.rds\")\np_cell &lt;- readRDS(\"data/procedure1/pseudobulk_celltype_sum.rds\")\ndata = list(\"pseudo_bulk_overall\" = p, \"pseudo_bulk_cell\" = p_cell)\nclusters &lt;- readRDS(\"data/procedure1/cluster_result_ER_and_PR_onlyER+PR+.rds\")\n\nThe first and second command respectively read in the bulked and pseudobulked transcriptomic datasets for the 54 individuals.\nBoth datasets are combined into a list structure for downstream analysis.\nThe final command reads in the clustering outcome to be predicted.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#cross-validated-classification",
    "href": "Procedure1.html#cross-validated-classification",
    "title": "2  Procedure 1",
    "section": "2.3 Cross-validated Classification",
    "text": "2.3 Cross-validated Classification\n3. Classifying patients into clusters\nTiming ~ 17.0s\n\nset.seed(1)\nnFeatures = list(pseudo_bulk_overall = 0.05*ncol(p), pseudo_bulk_cell = 0.05*ncol(p_cell))\nclassifyr_result3 &lt;- crossValidate(data, outcome = clusters$cluster, classifier = \"SVM\", nFeatures = nFeatures, nFolds = 5, nRepeats = 100, nCores = 5)\n\nThe set.seed(1) command ensures that any subsequent operations involving randomness yield consistent results across runs.\nThe second command defines the number of features to be selected. Here, it is set to 5% of the available features in each dataset.\nThe final command uses the crossValidate function to perform 5-fold cross-validation with the SVM classifier on both datasets. This process is repeated 100 times and utilizes 5 CPU cores for parallel processing to speed up classification. The type of classifier, number of folds, repeats and cores used can be adjusted as wished for different analyses.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#classification-evaluation",
    "href": "Procedure1.html#classification-evaluation",
    "title": "2  Procedure 1",
    "section": "2.4 Classification Evaluation",
    "text": "2.4 Classification Evaluation\n4. Classification Accuracy\nTiming ~ 0.21s\n\nclassifyr_result3 &lt;- sapply(classifyr_result3, function(results) {\n  calcCVperformance(results, performanceType = \"Sample Accuracy\")\n}) # loop to calculate sample accuracy\naccuracyMatrix &lt;- sapply(classifyr_result3, function(result) performance(result)[[\"Sample Accuracy\"]])\n\nThe first function uses calcCVperfomance to calculate the classification sample accuracy for both datasets.\nThe second function uses performance to output a matrix of sample accuracies.\n5. Classification Performance Visualisation\nTiming ~ 1.7s\n\nperformancePlot(classifyr_result3)\n\n\n\n\n\n\n\n\nperformancePlot outputs a side-by-side boxplot of the balanced accuracies for each dataset.\nBoth methods perform comparably in terms of median balanced accuracy, but the smaller range and interquartile range in balanced accuracy of the bulked datasets suggests it may be preferable for more consistent results.\n\nsamplesMetricMap(classifyr_result3)\n\n\n\n\n\n\n\n\nTableGrob (2 x 1) \"arrange\": 2 grobs\n  z     cells    name                grob\n1 1 (2-2,1-1) arrange      gtable[layout]\n2 2 (1-1,1-1) arrange text[GRID.text.276]\n\n\nsamplesMetricMap outputs a heatmap showing the classification accuracy for each of 100 repeats in each sample. A greater proportion of samples show high sample accuracies (0.8,1] when classified by the bulked data as opposed to the pseudobulked data.\n\nplot(accuracyMatrix) #scatterplot of sample accuracies for both datasets\n\n\n\n\n\n\n\n\nThe final command outputs a scatterplot to show the prediction accuracy of each sample in each dataset.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1</span>"
    ]
  }
]