[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ClassifyR PlayBook",
    "section": "",
    "text": "1 Overview",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "ClassifyR PlayBook",
    "section": "1.1 Welcome!",
    "text": "1.1 Welcome!\ntext",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#ummm",
    "href": "index.html#ummm",
    "title": "ClassifyR PlayBook",
    "section": "1.2 ummm",
    "text": "1.2 ummm\nmore text",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "Procedure1.html",
    "href": "Procedure1.html",
    "title": "2  Procedure 1",
    "section": "",
    "text": "2.1 Intro\ntext",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#next-thing",
    "href": "Procedure1.html#next-thing",
    "title": "2  Procedure 1",
    "section": "2.2 Next thing",
    "text": "2.2 Next thing\nmore text\n\nlibrary(ClassifyR)\nlibrary(sparsediscrim)\nlibrary(tidyverse)\nlibrary(SingleCellExperiment)\nlibrary(openxlsx)\nlibrary(pROC)\nlibrary(ggplot2)\nlibrary(reshape2)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1</span>"
    ]
  },
  {
    "objectID": "Procedure2.html",
    "href": "Procedure2.html",
    "title": "3  Procedure 2",
    "section": "",
    "text": "3.1 Intro\ntext",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procedure 2</span>"
    ]
  },
  {
    "objectID": "Procedure2.html#next-thing",
    "href": "Procedure2.html#next-thing",
    "title": "3  Procedure 2",
    "section": "3.2 Next thing",
    "text": "3.2 Next thing\nmore text",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procedure 2</span>"
    ]
  },
  {
    "objectID": "Procedure3.html",
    "href": "Procedure3.html",
    "title": "4  Procedure 3",
    "section": "",
    "text": "4.1 Intro\ntext",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Procedure 3</span>"
    ]
  },
  {
    "objectID": "Procedure3.html#next-thing",
    "href": "Procedure3.html#next-thing",
    "title": "4  Procedure 3",
    "section": "4.2 Next thing",
    "text": "4.2 Next thing\nmore text",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Procedure 3</span>"
    ]
  },
  {
    "objectID": "Procedure4.html",
    "href": "Procedure4.html",
    "title": "5  Procedure 4",
    "section": "",
    "text": "5.1 Intro\ntext",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Procedure 4</span>"
    ]
  },
  {
    "objectID": "Procedure4.html#next-thing",
    "href": "Procedure4.html#next-thing",
    "title": "5  Procedure 4",
    "section": "5.2 Next thing",
    "text": "5.2 Next thing\nmore text",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Procedure 4</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#simplified",
    "href": "Procedure1.html#simplified",
    "title": "2  Procedure 1",
    "section": "2.3 Simplified",
    "text": "2.3 Simplified\n\nset.seed(1)\nclinical = read.xlsx(\"clinical.xlsx\")\nclusters &lt;- readRDS(\"cluster_result_ER_and_PR_onlyER+PR+.rds\")\np &lt;- readRDS(\"pseudobulk_overall_sum.rds\") \np &lt;-p[rownames(p) %in% clusters$sample_id, ]\np_cell &lt;- readRDS(\"pseudobulk_celltype_sum.rds\")\np_cell &lt;-p_cell[rownames(p_cell) %in% clusters$sample_id, ]\noutcome = clusters$cluster\n\nclassifyr_result &lt;- crossValidate(p, outcome = outcome, selectionMethod = \"auto\", classifier = \"SVM\", nFeatures = 0.05 * nrow(p), nFolds = 5, nRepeats = 5, nCores = 5, characteristicsLabel = \"overall_pseudobulking\")\nclassifyr_result2 &lt;- crossValidate(p_cell, outcome = outcome, selectionMethod = \"auto\", classifier = \"SVM\", nFeatures = 0.05 * nrow(p_cell), nFolds = 5, nRepeats = 5, nCores = 5, characteristicsLabel = \"cell_specific_pseudobulking\")\nresults_both = append(classifyr_result, classifyr_result2)\nresults_both &lt;- lapply(results_both, function(results) {\n  calcCVperformance(results, performanceType = \"Balanced Accuracy\")\n})\nperformancePlot(results_both, characteristicsList = list(x = \"auto\", fillColour = \"characteristicsLabel\")) + theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) #performancePlot is essentially ggplot, so just add one more things\n\n\n\n\n\n\n\n\n\n# classifier must exactly match these options: randomForest, DLDA, kNN, GLM, ridgeGLM, elasticNetGLM, LASSOGLM, SVM, NSC, naiveBayes, mixturesNormals, CoxPH, CoxNet, randomSurvivalForest, XGB\n\n# Perform cross-validation for each classifier\nclassifyr_result &lt;- crossValidate(\n    p,  \n    outcome = outcome,  \n    selectionMethod = \"auto\", \n    classifier = c(\"SVM\", \"kNN\", \"randomForest\", \n               \"naiveBayes\", \"XGB\"), # Use the current classifier in the loop. but result will be a list of objects so it can't be put into calcCVperformance\n    nFeatures = 0.05 * nrow(p), \n    nFolds = 5,              \n    nRepeats = 5,            \n    nCores = 5,\n    characteristicsLabel = \"overall_pseudobulking\"\n)\n\n\nclassifyr_result2 &lt;- crossValidate(\n    p_cell,  \n    outcome = outcome,  \n    selectionMethod = \"auto\", \n    classifier = c(\"SVM\"), # Use the current classifier in the loop. but result will be a list of objects so it can't be put into calcCVperformance\n    nFeatures = 0.05 * nrow(p_cell), \n    nFolds = 5,              \n    nRepeats = 5,            \n    nCores = 5,\n    characteristicsLabel = \"cell_specific_pseudobulking\"\n  )\n\nresults_both = append(classifyr_result, classifyr_result2)\n\nresults_both &lt;- lapply(results_both, function(results) {\n  calcCVperformance(results, performanceType = \"Balanced Accuracy\")\n})\n\nperformancePlot(results_both, characteristicsList = list(x = \"auto\", fillColour = \"characteristicsLabel\")) + theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) #performancePlot is essentially ggplot, so just add one more things",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#overall-pseudobulked-data",
    "href": "Procedure1.html#overall-pseudobulked-data",
    "title": "2  Procedure 1",
    "section": "3.2 Overall Pseudobulked Data",
    "text": "3.2 Overall Pseudobulked Data\n\nclinical = read.xlsx(\"clinical.xlsx\")\noutcome = substring(clinical$OS_STATUS,1,1)\n\np &lt;- readRDS(\"pseudobulk_overall_sum.rds\")\np_filtered &lt;- p[, colSums(p != 0) &gt; 0, drop = FALSE]\n\np_values &lt;- sapply(colnames(p_filtered), function(feature) {\n  t.test(p_filtered[[feature]] ~ outcome, na.action = na.omit)$p.value\n})\nselected_features &lt;- colnames(p_filtered)[p_values &lt; 0.05]\ncat(\"The selected features by cell-specific pseudobulking using an fdr of 0.05 are:\\n\", \n    paste(selected_features, collapse = \", \"), \"\\n\")\n\nThe selected features by cell-specific pseudobulking using an fdr of 0.05 are:\n ADGRE5, AIF1, FGL2, FOXC2, GLIPR1, ITM2C, LDHB, MMP12, S100A4, SMAP2, SSTR2, TCEAL7, TOMM7 \n\nomics_selected &lt;- p_filtered[,selected_features]  # Subset omics data\nnFeatures &lt;- list(omics = 1:length(selected_features))\n\nclassifyr_result &lt;- crossValidate(\n  list(omics = omics_selected),  # Only use omics data\n  outcome = outcome,  # Use the outcome column\n  extraParams = list(prepare = list(useFeatures = list(omics = selected_features))),\n  nFeatures = nFeatures,\n  nFolds = 5,       # 5-fold cross-validation\n  nRepeats = 5,     # 5 repeats\n  nCores = 5        # Parallel processing with 5 cores\n)\nsaveRDS(classifyr_result, file = \"classifyr_result.rds\")\n\nclassifyr_result_forest &lt;- crossValidate(\n  list(omics = omics_selected),  # Only use omics data\n  outcome = outcome,  # Use the outcome column\n  extraParams = list(prepare = list(useFeatures = list(omics = selected_features))),\n  nFeatures = nFeatures,\n  classifier = \"randomForest\",\n  nFolds = 5,       # 5-fold cross-validation\n  nRepeats = 5,     # 5 repeats\n  nCores = 5        # Parallel processing with 5 cores\n)\n\n\n3.2.1 Performance comparison between Cox proportional hazards & random survival forest\n\n# Extract predictions\npredictions &lt;- predictions(classifyr_result)\nnamed_outcomes &lt;- setNames(as.list(outcome),clinical$patientId)\n# Actual outcomes\npredictions$actual &lt;- named_outcomes\npredictions$actual &lt;- unlist(predictions$actual)\n# Generate the confusion matrix\nconfusion_matrix &lt;- table(Predicted = predictions$class, Actual = predictions$actual)\nprint(confusion_matrix)\n\n         Actual\nPredicted   0   1\n        0 393  45\n        1  22   0\n\n#Performance Metrics\nTP &lt;- diag(confusion_matrix)\nFN &lt;- rowSums(confusion_matrix) - TP\nFP &lt;- colSums(confusion_matrix) - TP\nTN &lt;- sum(confusion_matrix) - (TP + FP + FN)\nsensitivity &lt;- TP / (TP + FN) # Recall or Sensitivity\nspecificity &lt;- TN / (TN + FP) # Specificity\nprecision &lt;- TP / (TP + FP)   # Precision\naccuracy &lt;- sum(TP) / sum(confusion_matrix)\nf1_score &lt;- 2 * (precision * sensitivity) / (precision + sensitivity)\ncat(\"Metrics for predictions from overall pseudobulking:\\n\")\n\nMetrics for predictions from overall pseudobulking:\n\ncat(\"Accuracy:\", accuracy, \"\\n\")\n\nAccuracy: 0.8543478 \n\ncat(\"Sensitivity (Recall) per class:\", sensitivity, \"\\n\")\n\nSensitivity (Recall) per class: 0.8972603 0 \n\ncat(\"Specificity per class:\", specificity, \"\\n\")\n\nSpecificity per class: 0 0.8972603 \n\ncat(\"Precision per class:\", precision, \"\\n\")\n\nPrecision per class: 0.946988 0 \n\ncat(\"F1 Score per class:\", f1_score, \"\\n\")\n\nF1 Score per class: 0.9214537 NaN \n\n#Confusion_matrix package to calculate everything: \n\n# Extract predictions\npredictions_forest &lt;- predictions(classifyr_result_forest)\npredictions_forest$actual &lt;- named_outcomes #actual outcome\npredictions_forest$actual &lt;- unlist(predictions_forest$actual)\n# Generate the confusion matrix\nconfusion_matrix_forest &lt;- table(Predicted = predictions_forest$class, Actual = predictions_forest$actual)\n# View the confusion matrix\nprint(confusion_matrix_forest)\n\n         Actual\nPredicted   0   1\n        0 395  45\n        1  20   0\n\nTP &lt;- diag(confusion_matrix_forest)\nFN &lt;- rowSums(confusion_matrix_forest) - TP\nFP &lt;- colSums(confusion_matrix_forest) - TP\nTN &lt;- sum(confusion_matrix_forest) - (TP + FP + FN)\n# Performance Metrics\nsensitivity &lt;- TP / (TP + FN) # Recall or Sensitivity\nspecificity &lt;- TN / (TN + FP) # Specificity\nprecision &lt;- TP / (TP + FP)   # Precision\naccuracy &lt;- sum(TP) / sum(confusion_matrix_forest)\nf1_score &lt;- 2 * (precision * sensitivity) / (precision + sensitivity)\n\ncat(\"Metrics for predictions from overall pseudobulking using random forest:\\n\")\n\nMetrics for predictions from overall pseudobulking using random forest:\n\ncat(\"Accuracy:\", accuracy, \"\\n\")\n\nAccuracy: 0.8586957 \n\ncat(\"Sensitivity (Recall) per class:\", sensitivity, \"\\n\")\n\nSensitivity (Recall) per class: 0.8977273 0 \n\ncat(\"Specificity per class:\", specificity, \"\\n\")\n\nSpecificity per class: 0 0.8977273 \n\ncat(\"Precision per class:\", precision, \"\\n\")\n\nPrecision per class: 0.9518072 0 \n\ncat(\"F1 Score per class:\", f1_score, \"\\n\")\n\nF1 Score per class: 0.9239766 NaN",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#cell-specific-pseudobulked-data",
    "href": "Procedure1.html#cell-specific-pseudobulked-data",
    "title": "2  Procedure 1",
    "section": "3.3 Cell-specific Pseudobulked Data",
    "text": "3.3 Cell-specific Pseudobulked Data\n\np_cell &lt;- readRDS(\"pseudobulk_celltype_sum.rds\")\np_cell_filtered &lt;- p_cell[, colSums(p_cell != 0) &gt; 0, drop = FALSE]\n\np_values_cell &lt;- sapply(colnames(p_cell_filtered), function(feature) {\n  t.test(p_cell_filtered[[feature]] ~ outcome, na.action = na.omit)$p.value\n})\n\nselected_cell_features &lt;- colnames(p_cell_filtered)[p_values_cell &lt; 0.05]\ncat(\"The selected features by cell-specific pseudobulking using an fdr of 0.05 are:\\n\", \n    paste(selected_cell_features, collapse = \", \"), \"\\n\")\n\nThe selected features by cell-specific pseudobulking using an fdr of 0.05 are:\n Stromal__SSTR2, Malignant__C5orf46, Malignant__CLEC9A, Malignant__MMP12, Malignant__TCEAL7, Malignant__TCL1A, T__SSTR2, T__TCEAL7, Macrophage__CLEC9A, Macrophage__FOXC2, Macrophage__MMP12, Macrophage__SSTR2, Macrophage__TCEAL7, Myoepi__FOXC2, DC_Mast__ADIPOQ, DC_Mast__C5orf46, DC_Mast__SCGB2A1, DC_Mast__SSTR2, DC_Mast__TCEAL7 \n\nomics_selected_cell &lt;- p_cell_filtered[,selected_cell_features]  # Subset omics data\nnFeatures_cell &lt;- list(omics = 1:length(selected_cell_features))\n\nclassifyr_result_cell &lt;- crossValidate(\n  list(omics = omics_selected_cell),  \n  outcome = outcome,  # Use the outcome column\n  extraParams = list(prepare = list(useFeatures = list(omics = selected_cell_features))),\n  nFeatures = nFeatures_cell,\n  nFolds = 5,       # 5-fold cross-validation\n  nRepeats = 5,     # 5 repeats\n  nCores = 5        # Parallel processing with 5 cores\n)\nsaveRDS(classifyr_result_cell, file = \"classifyr_result_cell.rds\")\n\nclassifyr_result_cell_forest &lt;- crossValidate(\n  list(omics = omics_selected_cell),  # Only use omics data\n  outcome = outcome,  # Use the outcome column\n  extraParams = list(prepare = list(useFeatures = list(omics = selected_cell_features))),\n  nFeatures = nFeatures_cell,\n  classifier = \"randomForest\",\n  nFolds = 5,       # 5-fold cross-validation\n  nRepeats = 5,     # 5 repeats\n  nCores = 5        # Parallel processing with 5 cores\n)\n\n\n3.3.1 Performance comparison between Cox proportional hazards & random survival forest\n\n# Extract predictions\npredictions_cell &lt;- predictions(classifyr_result_cell)\nnamed_outcomes &lt;- setNames(as.list(outcome),clinical$patientId)\n# Actual Outcomes\npredictions_cell$actual &lt;- named_outcomes\npredictions_cell$actual &lt;- unlist(predictions_cell$actual)\n# Generate the confusion matrix\nconfusion_matrix_cell &lt;- table(Predicted = predictions_cell$class, Actual = predictions_cell$actual)\nprint(confusion_matrix_cell)\n\n         Actual\nPredicted   0   1\n        0 403  43\n        1  12   2\n\nTP &lt;- diag(confusion_matrix_cell)\nFN &lt;- rowSums(confusion_matrix_cell) - TP\nFP &lt;- colSums(confusion_matrix_cell) - TP\nTN &lt;- sum(confusion_matrix_cell) - (TP + FP + FN)\n# Performance Metrics\nsensitivity &lt;- TP / (TP + FN) # Recall or Sensitivity\nspecificity &lt;- TN / (TN + FP) # Specificity\nprecision &lt;- TP / (TP + FP)   # Precision'accuracy &lt;- sum(TP) / sum(confusion_matrix_cell_forest)\naccuracy &lt;- sum(TP) / sum(confusion_matrix_cell)\nf1_score &lt;- 2 * (precision * sensitivity) / (precision + sensitivity)\ncat(\"Metrics for predictions from cell-specific pseudobulking:\\n\")\n\nMetrics for predictions from cell-specific pseudobulking:\n\ncat(\"Accuracy:\", accuracy, \"\\n\")\n\nAccuracy: 0.8804348 \n\ncat(\"Sensitivity (Recall) per class:\", sensitivity, \"\\n\")\n\nSensitivity (Recall) per class: 0.9035874 0.1428571 \n\ncat(\"Specificity per class:\", specificity, \"\\n\")\n\nSpecificity per class: 0.1428571 0.9035874 \n\ncat(\"Precision per class:\", precision, \"\\n\")\n\nPrecision per class: 0.9710843 0.04444444 \n\ncat(\"F1 Score per class:\", f1_score, \"\\n\")\n\nF1 Score per class: 0.9361208 0.06779661 \n\n# Extract predictions\npredictions_cell_forest &lt;- predictions(classifyr_result_cell_forest)\npredictions_cell_forest$actual &lt;- named_outcomes #actual outcome\npredictions_cell_forest$actual &lt;- unlist(predictions_cell_forest$actual)\n# Generate the confusion matrix\nconfusion_matrix_cell_forest &lt;- table(Predicted = predictions_cell_forest$class, Actual = predictions_cell_forest$actual)\n# View the confusion matrix\nprint(confusion_matrix_cell_forest)\n\n         Actual\nPredicted   0   1\n        0 399  45\n        1  16   0\n\n# Total True Positives (TP), True Negatives (TN), False Positives (FP), False Negatives (FN)\nTP &lt;- diag(confusion_matrix_cell_forest)\nFN &lt;- rowSums(confusion_matrix_cell_forest) - TP\nFP &lt;- colSums(confusion_matrix_cell_forest) - TP\nTN &lt;- sum(confusion_matrix_cell_forest) - (TP + FP + FN)\n\n# Calculating metrics for each class\nsensitivity &lt;- TP / (TP + FN) # Recall or Sensitivity\nspecificity &lt;- TN / (TN + FP) # Specificity\nprecision &lt;- TP / (TP + FP)   # Precision\naccuracy &lt;- sum(TP) / sum(confusion_matrix_cell_forest)\nf1_score &lt;- 2 * (precision * sensitivity) / (precision + sensitivity)\n\ncat(\"Metrics for predictions from cell-specific pseudobulking using random forest:\\n\")\n\nMetrics for predictions from cell-specific pseudobulking using random forest:\n\ncat(\"Accuracy:\", accuracy, \"\\n\")\n\nAccuracy: 0.8673913 \n\ncat(\"Sensitivity (Recall) per class:\", sensitivity, \"\\n\")\n\nSensitivity (Recall) per class: 0.8986486 0 \n\ncat(\"Specificity per class:\", specificity, \"\\n\")\n\nSpecificity per class: 0 0.8986486 \n\ncat(\"Precision per class:\", precision, \"\\n\")\n\nPrecision per class: 0.9614458 0 \n\ncat(\"F1 Score per class:\", f1_score, \"\\n\")\n\nF1 Score per class: 0.9289872 NaN",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#final-procedure-using-scm-classifier-with-5-of-features-selected-from-t-test",
    "href": "Procedure1.html#final-procedure-using-scm-classifier-with-5-of-features-selected-from-t-test",
    "title": "2  Procedure 1",
    "section": "2.3 Final Procedure using SCM Classifier with 5% of features selected from t-test",
    "text": "2.3 Final Procedure using SCM Classifier with 5% of features selected from t-test\n\nset.seed(1)\nclinical = read.xlsx(\"clinical.xlsx\")\nclusters &lt;- readRDS(\"cluster_result_ER_and_PR_onlyER+PR+.rds\")\np &lt;- readRDS(\"pseudobulk_overall_sum.rds\") \np &lt;-p[rownames(p) %in% clusters$sample_id, ]\np_cell &lt;- readRDS(\"pseudobulk_celltype_sum.rds\")\np_cell &lt;-p_cell[rownames(p_cell) %in% clusters$sample_id, ]\noutcome = clusters$cluster\n\nclassifyr_result &lt;- crossValidate(p, outcome = outcome, selectionMethod = \"auto\", classifier = \"SVM\", nFeatures = 0.05 * nrow(p), nFolds = 5, nRepeats = 5, nCores = 5, characteristicsLabel = \"overall_pseudobulking\")\nclassifyr_result2 &lt;- crossValidate(p_cell, outcome = outcome, selectionMethod = \"auto\", classifier = \"SVM\", nFeatures = 0.05 * nrow(p_cell), nFolds = 5, nRepeats = 5, nCores = 5, characteristicsLabel = \"cell_specific_pseudobulking\")\nresults_both = append(classifyr_result, classifyr_result2)\nresults_both &lt;- lapply(results_both, function(results) {\n  calcCVperformance(results, performanceType = \"Balanced Accuracy\")\n})\nperformancePlot(results_both, characteristicsList = list(x = \"auto\", fillColour = \"characteristicsLabel\")) + theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) #performancePlot is essentially ggplot, so just add one more things",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#everything-below-is-verbose-non-classifyr-code-left-in-for-comparison",
    "href": "Procedure1.html#everything-below-is-verbose-non-classifyr-code-left-in-for-comparison",
    "title": "2  Procedure 1",
    "section": "3.1 Everything below is verbose non-ClassifyR Code (Left in for comparison)",
    "text": "3.1 Everything below is verbose non-ClassifyR Code (Left in for comparison)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1</span>"
    ]
  }
]