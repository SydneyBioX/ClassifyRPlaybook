[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ClassifyR PlayBook",
    "section": "",
    "text": "1 Overview",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#precision-medicine-and-the-need-for-advanced-classification-tools",
    "href": "index.html#precision-medicine-and-the-need-for-advanced-classification-tools",
    "title": "ClassifyR PlayBook",
    "section": "1.1 Precision medicine and the need for advanced classification tools",
    "text": "1.1 Precision medicine and the need for advanced classification tools\nPrecision medicine is a personalised approach to healthcare that tailors prevention, diagnosis, and treatment to an individual’s unique characteristics such as genetics, environment, lifestyle, and molecular data. By integrating diverse data types, the ultimate goal of precision medicine is to deliver the right decision or treatment to the right patient at the right time. While this has driven the development of complex classification strategies, realising this vision relies on robust evaluation of model performance at both cohort and patient levels. \n\n1.1.1 What is ClassifyR?\nThis playbook presents ClassifyR, a comprehensive machine learning framework tailored for multi-omics classification problems in a precision medicine context. ClassifyR was first introduced in 2015 as a tool for assessing classification performance in omics research, particularly evaluating feature selection approaches in transcriptomics (Strbenac et al., 2015). It provides systematic comparison of predictive models, emphasising accuracy, stability and interpretability. While machine learning evaluation frameworks such as caret and mlr in R and scikit-learn in Python provide general-purpose machine learning frameworks, they lack specific capabilities for pre-processing, feature selection, feature interrogation, multi-omic integration and cross-platform performance evaluation. Standardising these procedures into a unified framework can facilitate more systematic and robust evaluations. Thus, ClassifyR distinguishes itself in multiple ways:\n\nBioconductor ecosystem integration: ClassifyR is interoperable with established omics data structures in the Bioconductor Project, ensuring seamless access to single-cell, multi-omics, and spatial technologies.\nFull cross-validation workflow: The package performs comprehensive cross-validation by including feature selection and hyperparameter tuning within the cross-validation procedure, which is essential for handling large-scale omics datasets.\nCross-dataset and cross-modality validation: Models can be both constructed and evaluated across cohorts and omics platforms, addressing issues of reproducibility and transferability.\nPrecision medicine focus: ClassifyR includes frameworks for assessing model appropriateness at an individual patient level which is crucial for evaluating which model or modality is appropriate for which patient.\n\nBy addressing these critical gaps, ClassifyR enables researchers to explore complex disease mechanisms, optimise diagnostic workflows, and guide treatment strategies in precision medicine.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "Procedure1.html",
    "href": "Procedure1.html",
    "title": "2  Procedure 1: Comparing cross-validated results",
    "section": "",
    "text": "2.1 Introduction\nProcedure 1 aims to compare the sample accuracy of breast cancer subtype classification using bulk gene expression data and histologically predicted gene expression data. Sample accuracy is defined as the proportion of correctly predicted classifications over multiple repeats. For example, if 70 out of 100 repeats correctly classify an individual, their sample accuracy is 0.70.\nThis analysis involves 54 oestrogen receptor-positive (ER+) and progesterone receptor-positive (PR+) breast cancer patients, with each assay containing expression values for 268 genes. The classification outcomes are ‘Subtype 1’ and ‘Subtype 2’, found by unsupervised machine learning. Subtype 1 corresponds to patients with higher expression of LPL, CAVIN2, and TIMP4 in macrophage cells, and ADIPOQ in stromal cells, associated with better survival. Subtype 2 is the opposite, associated with poorer survival. More details on the subtypes can be found at https://www.biorxiv.org/content/10.1101/2024.07.02.601790v1.full.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1: Comparing cross-validated results</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#setting-up-the-environment-and-data-objects",
    "href": "Procedure1.html#setting-up-the-environment-and-data-objects",
    "title": "2  Procedure 1: Comparing cross-validated results",
    "section": "2.2 Setting up the environment and data objects",
    "text": "2.2 Setting up the environment and data objects\n1. Load the R packages into the R environment\nTiming ~ 6.5s\n\nlibrary(ClassifyR)\n\nClassifyR is used to perform all the demonstrated analyses.\n2. Import preprocessed datasets for analysis\nTiming ~ 0.04s\n\nghist_mae &lt;- readRDS(\"data/procedure1/ghist_multiassayexperiment.rds\")\n\nThis command reads in a MultiAssayExperiment with two assays. The first is bulk gene expression data for 54 breast cancer individuals and the second is bulk gene expression as predicted from histological images of the same individuals. They are respectively named bulk_gene_expression and histologically_predicted_gene_expression.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1: Comparing cross-validated results</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#cross-validated-classification",
    "href": "Procedure1.html#cross-validated-classification",
    "title": "2  Procedure 1: Comparing cross-validated results",
    "section": "2.3 Cross-validated Classification",
    "text": "2.3 Cross-validated Classification\n3. Classifying patients into subtype outcomes\nTiming ~ 45.0s\n\nset.seed(1)\nclassifyr_result &lt;- crossValidate(ghist_mae, outcome = \"subtype\", nFolds = 5, nRepeats = 100, nCores = 5)\n\nThe set.seed(1) command ensures that any subsequent operations involving randomness yield consistent results across runs.\nThe next command uses the crossValidate function to perform 5-fold cross-validation with the automatically selected RandomForest classifier on both datasets. This process is repeated 100 times and utilizes 5 CPU cores for parallel processing to speed up classification. The type of classifier, number of folds, repeats and cores used can be adjusted as wished for different analyses. The outcome here is “subtype”, a column from colData(ghist_mae) containing the two breast cancer subtypes to be predicted.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1: Comparing cross-validated results</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#classification-evaluation",
    "href": "Procedure1.html#classification-evaluation",
    "title": "2  Procedure 1: Comparing cross-validated results",
    "section": "2.4 Classification Evaluation",
    "text": "2.4 Classification Evaluation\n4. Visualising the classification performance\nTiming ~ 1.75s\n\nperformancePlot(classifyr_result)\n\n\n\n\n\n\n\n\nperformancePlot outputs a side-by-side boxplot of the balanced accuracies for each dataset.\nBoth methods perform comparably in terms of median balanced accuracy and also demonstrate similar distributions of performance as seen from the comparable interquartile range and range. There does not appear to be much difference in the classification performance of both assays.\n\nsamplesMetricMap(classifyr_result)\n\n\n\n\n\n\n\n\nTableGrob (2 x 1) \"arrange\": 2 grobs\n  z     cells    name                grob\n1 1 (2-2,1-1) arrange      gtable[layout]\n2 2 (1-1,1-1) arrange text[GRID.text.274]\n\n\nsamplesMetricMap outputs a heatmap showing the classification accuracy for each of 100 repeats in each sample. A greater proportion of samples show high sample accuracies (0.8,1] when classified by the expression data as opposed to the histological data.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1: Comparing cross-validated results</span>"
    ]
  },
  {
    "objectID": "Procedure2.html",
    "href": "Procedure2.html",
    "title": "3  Procedure 2: Multi-view classifiability evaluation",
    "section": "",
    "text": "3.1 Introduction\nClassifyR implements a variety of ways to evaluate the classifiability of samples from multiple views. A view could be an omics assay or it could be a particular metafeature generation of a particular data set.\nIn this case study, both different assays and different metafeatures will be demonstrated of the widely-known METABRIC breast cancer data set. These have been pre-generated. Briefly,\nThe subset of samples which have no detected lymph node metastasis, irrespective of stage, are used for subsequent analysis.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procedure 2: Multi-view classifiability evaluation</span>"
    ]
  },
  {
    "objectID": "Procedure2.html#introduction",
    "href": "Procedure2.html#introduction",
    "title": "3  Procedure 2: Multi-view classifiability evaluation",
    "section": "",
    "text": "Clinical: Contains the outcome of interest (recurrence-free survival) as well as covariates that could predict it, such as tumour size and grade.\nRNA abundance: This was measured by microarrays. Quantile normalisation and prove reannotation was made by cBioPortal. Top 2000 highly-variable genes are used for illustration.\nImaging mass cytometry: Complementary to RNA, this assay gives the protein abundances for a small panel of 39 proteins. This is the basis of:\n\nType Proportions: Using annotated cell types, the proportion of each cell type in each patient sample.\nType Protein Mean: For each cell type, the average abundance of each feature in each sample.\nType Pairs Colocated: For each pair of cell types, a score of association using their X and Y coordinates based on L curve.\nColocated in Regions: k-means clustering-based definition of regions and spatial association within them.\nProportions of Parent: Based on HOPACH hierarchical clustering, the proportion of a cell type to its parent type.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procedure 2: Multi-view classifiability evaluation</span>"
    ]
  },
  {
    "objectID": "Procedure2.html#setting-up-the-environment-and-data-objects",
    "href": "Procedure2.html#setting-up-the-environment-and-data-objects",
    "title": "3  Procedure 2: Multi-view classifiability evaluation",
    "section": "3.2 Setting up the environment and data objects",
    "text": "3.2 Setting up the environment and data objects\n1. Load the R packages into the R environment\nThe first step is to load the data and look at a few records (2 minutes).\nTiming ~ 6.5s\n\nlibrary(ClassifyR)\nlibrary(ggplot2)\n\nClassifyR is used to perform all the demonstrated analyses below.\n2. Import preprocessed datasets for analysis\nTiming ~ 0.057s\n\nMETABRIC &lt;- readRDS(\"data/procedure2/METABRICviews.rds\")\nsapply(METABRIC, dim)\n\n     clinical RNA Microarray Type Proportions Type Protein Mean\n[1,]      165            165              165               165\n[2,]       30           2000               22               858\n     Type Pairs Colocated Colocated in Regions Proportion of Parent\n[1,]                  165                  165                  165\n[2,]                  484                   10                   55\n\n\nThe number of features vary from 10 to 2000 for 165 patients. Next, look more closely at clinical data.\nTiming ~ 0.055s\n\nhead(METABRIC[[\"clinical\"]])\n\n        METABRIC.ID MATCHED.NORMAL.METABRIC.ID Cohort Age.At.Diagnosis\nMB-0002     MB-0002                    MB-0003      1            43.19\nMB-0010     MB-0010                    MB-0011      1            78.77\nMB-0035     MB-0035                    MB-0034      1            84.22\nMB-0060     MB-0060                    MB-0061      1            45.43\nMB-0081     MB-0081                    MB-0080      1            49.61\nMB-0107     MB-0107                    MB-0676      1            65.59\n        Breast.Tumour.Laterality Date.Of.Diagnosis Last.Followup.Status   NPI\nMB-0002                        r           2000/12                    a 4.020\nMB-0010                        l           2001/03               d-d.s. 4.062\nMB-0035                        l           2001/04               d-d.s. 3.056\nMB-0060                        r           2001/07                    a 4.046\nMB-0081                        r           2001/08                    a 3.048\nMB-0107                        r           2001/12                    a 4.036\n        ER.Status Inferred.Menopausal.State Lymph.Nodes.Positive\nMB-0002       pos                       pre                    0\nMB-0010       pos                      post                    0\nMB-0035       neg                      post                    0\nMB-0060       pos                       pre                    0\nMB-0081       pos                       pre                    0\nMB-0107       pos                      post                    0\n           Breast.Surgery    CT    HT    RT Grade Size Histological.Type Stage\nMB-0002 BREAST CONSERVING NO/NA   TAM    CW     3   10               IDC     1\nMB-0010        MASTECTOMY NO/NA   TAM    CW     3   31               IDC     4\nMB-0035        MASTECTOMY NO/NA NO/NA NO/NA     2   28               ILC     2\nMB-0060 BREAST CONSERVING    AC   TAM    CW     3   23               IDC     2\nMB-0081 BREAST CONSERVING NO/NA GNRHA    CW     2   24               IDC     2\nMB-0107        MASTECTOMY NO/NA   TAM NO/NA     3   18               IDC     2\n        DeathBreast Death    T  TLR LR  TDR DR Complete.Rec.History metabricId\nMB-0002           0     0 2539 2539  0 2539  0                  YES    MB-0002\nMB-0010           1     1  234  234  0   88  1                  YES    MB-0010\nMB-0035           1     1 1088 1088  0 1088  0                  YES    MB-0035\nMB-0060           0     0 4226 4226  0 4226  0                  YES    MB-0060\nMB-0081           0     0 2085 2085  0 2085  0                  YES    MB-0081\nMB-0107           0     0 4741 4741  0 4741  0                  YES    MB-0107\n        timeRFS eventRFS\nMB-0002    2539        0\nMB-0010      88        1\nMB-0035    1088        1\nMB-0060    4226        0\nMB-0081    2085        0\nMB-0107    4741        0\n\ntable(METABRIC[[\"clinical\"]][, \"Lymph.Nodes.Positive\"])\n\n\n  0 \n165 \n\nusefulFeatures &lt;- c(\"Breast.Tumour.Laterality\", \"ER.Status\", \"Inferred.Menopausal.State\",\n                    \"Grade\", \"Size\", \"Stage\")\n\ntimeRFS and eventRFS columns will form the outcomes to predict.\nClinical data often has arbitrary sample identifiers, dates and other non-biological information which should not be used in model building. Define a set of useful features for further use.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procedure 2: Multi-view classifiability evaluation</span>"
    ]
  },
  {
    "objectID": "Procedure2.html#model-building-and-evaluation",
    "href": "Procedure2.html#model-building-and-evaluation",
    "title": "3  Procedure 2: Multi-view classifiability evaluation",
    "section": "3.3 Model Building and Evaluation",
    "text": "3.3 Model Building and Evaluation\nExamine whether any view alone is the best predictor or whether combinations of views add value to accuracy. Note that any parameters to the prepare element of extraParams will be passed to the prepareData function.\n3. Individual Assays\nTiming ~ 120s\nThe first analysis fits a penalised Cox proportional hazards model to each assay alone. Remember that the default scheme of crossValidate is 5-fold cross-validation repeated 20 times.\n\nset.seed(2024)\ncoxPredicts &lt;- crossValidate(METABRIC, c(\"timeRFS\", \"eventRFS\"),\n                             selectionMethod = \"CoxPH\", classifier = \"CoxNet\", nCores = 20,\n                             extraParams = list(prepare = list(useFeatures = list(clinical = usefulFeatures))))\norderViews &lt;- c(\"clinical\", \"RNA Microarray\", \"Type Proportions\",\n                 \"Proportion of Parent\", \"Colocated in Regions\", \"Type Protein Mean\", \"Type Pairs Colocated\")\nperformancePlot(coxPredicts, orderingList = list(`Assay Name` = orderViews)) +\n    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))\n\n\n\n\n\n\n\nforMerge &lt;- c(\"clinical\", \"RNA Microarray\", \"Type Proportions\", \"Type Pairs Colocated\")\n\nThe most accurate view is Proportion of Parent but using only the freely available clinical data is qualitatively the same as omics. It is also interesting to observe that protein assay has better predicted performance although it has about a hundred times less features to use than RNA does.\nTiming ~ 26s\n\nperSampleC &lt;- samplesMetricMap(coxPredicts[c(1:3, 7)], showXtickLabels = FALSE)\n\nWarning in .local(results, ...): Sample C-index not found in all elements of\nresults. Calculating it now.\n\n\n\n\n\n\n\n\n\nIt is also worthwhile looking at per-sample C-index, which is simply the number of concordant pairs divided by the total number of feasible pairs of sample comparisons between the predicted risk score and the event-time recorded outcome.\n4. Individual Assays\nTiming ~ 21.2mins\nAlthough it is possible to exhaustively combine all possible subsets of the seven views, the large number of box plots becomes difficult to interpret. Hence, clinical, RNA and two imaging mass cytometry views Proportion of Parent (best individual view) and Type Proportions (worst individual view) will be included.\nFirstly, \"merge\" combination mode is used, which simply concatenates the features independently chosen for each view. (8 minutes)\n\ncoxMergePredicts &lt;- crossValidate(METABRIC[forMerge], c(\"timeRFS\", \"eventRFS\"), multiViewMethod = \"merge\",\n                                  extraParams = list(prepare = list(useFeatures = list(clinical = usefulFeatures))),\n                                  selectionMethod = \"CoxPH\", classifier = \"CoxNet\", nCores = 20)\nperformancePlot(coxMergePredicts, orderingList = list(\"Assay Name\" = \"performanceDescending\"))\n\n\n\n\n\n\n\n\nCombining clinical data with an imaging mass cytometry view has the best overall performance and slightly better than either view alone.\nAn alternative to simply concatenating features is to do prevalidation. Training and prediction is applied to each non-clinical view and the preiction is added as a column to the clinical data. Hence, each high-dimensional omics view become a single feature in the clinical data table. If omics views are indeed important they should out-compete clinical variables during feature selection.\nTo perform prevalidation, specify multiViewMethod = \"prevalidation\" (17 minutes)\nTiming ~ 46.6mins\n\ncoxPrevalPredicts &lt;- crossValidate(METABRIC[forMerge], c(\"timeRFS\", \"eventRFS\"),\n                     extraParams = list(prepare = list(useFeatures = list(clinical = usefulFeatures))),\n                     multiViewMethod = \"prevalidation\", nRepeats = 20,\n                     selectionMethod = \"CoxPH\", classifier = \"CoxNet\", nCores = 20)\n\nperformancePlot(coxPrevalPredicts)\n\n\n\n\n\n\n\n\nExamine the features selected for when RNA data augmented the clinical data.\nTiming ~ 0.03s\n\ncoxPrevalPredicts[[2]]\n\nAn object of class 'ClassifyResult'.\nCharacteristics:\n       characteristic                    value\n           Assay Name clinical, RNA Microarray\n      Classifier Name           CoxNet, CoxNet\n       Selection Name             CoxPH, CoxPH\n      multiViewMethod            prevalidation\n characteristicsLabel                     none\n     Cross-validation 20 Permutations, 5 Folds\nFeatures: List of length 39 of feature identifiers.\nPredictions: A data frame of 1280 rows.\nPerformance Measures: None calculated yet.\n\ndistribution(coxPrevalPredicts[[2]], plot = FALSE)\n\nallFeaturesText\n                    Grade  Breast.Tumour.Laterality Inferred.Menopausal.State \n                     1.00                      0.87                      0.87 \n                    Stage                 ER.Status                      Size \n                     0.87                      0.85                      0.82 \n\n\nThe omics views did not outcompete the clinical variables in this scenario.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procedure 2: Multi-view classifiability evaluation</span>"
    ]
  },
  {
    "objectID": "Procedure2.html#summary",
    "href": "Procedure2.html#summary",
    "title": "3  Procedure 2: Multi-view classifiability evaluation",
    "section": "3.4 Summary",
    "text": "3.4 Summary\nPatient survival of them METRABRIC dataset was examined in a variety of ways. Given the cost and expertise required for generating omics data, the value of omics data over and above easily obtainable clinical data was not identified.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procedure 2: Multi-view classifiability evaluation</span>"
    ]
  },
  {
    "objectID": "Procedure3.html",
    "href": "Procedure3.html",
    "title": "4  Procedure 3: Multi-Platform Precision Pathway",
    "section": "",
    "text": "4.1 Introduction\nProcedure 3 aims to construct a multi-platform precision pathway for determining the prognostic outcome of melanoma patients. This mimics a clinical diagnostic pathway, where given the results of a diagnostic test, a confident decision may be made, or the patient may be referred to collect more data from a different platform.\nFor this analysis, clinical data in addition to sequencing data from two platforms are employed for 62 samples and the data is accessible at Melanoma Explorer53. The first is an mRNA dataset assayed using Sentrix Human-6 v3 Expression BeadChips (Illumina, San Diego, CA). The second is a microRNA dataset with expression profiling performed using Agilent Technologies’ microRNA platform (version 16, Agilent Technologies, Santa Clara, CA). The prognosis outcome is classified as “Good” if survival is greater than 4 years from the date of tumor banking and “Poor” if survival is less than 1 year from the date of tumor banking. Patients who do not match a “Good” or “Poor” prognosis are excluded from analysis.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Procedure 3: Multi-Platform Precision Pathway</span>"
    ]
  },
  {
    "objectID": "Procedure3.html#setting-up-the-environment-and-data-objects",
    "href": "Procedure3.html#setting-up-the-environment-and-data-objects",
    "title": "4  Procedure 3: Multi-Platform Precision Pathway",
    "section": "4.2 Setting up the environment and data objects",
    "text": "4.2 Setting up the environment and data objects\n1. Load the R packages into the R environment\nTiming ~ 6.5s\n\nlibrary(ClassifyR)\n\nClassifyR is used to perform all the demonstrated analyses below.\n2. Import preprocessed datasets for analysis\nTiming ~ 0.82s\n\nmel_mae &lt;- readRDS(\"data/procedure3/MultiAssayExperiment.rds\")\ncolData(mel_mae)\n\nDataFrame with 62 rows and 4 columns\n             pathology_T_stage     Outcome       sex       age\n                     &lt;numeric&gt; &lt;character&gt; &lt;numeric&gt; &lt;integer&gt;\nTCGA-BF-A1PX                 5        Poor         2        56\nTCGA-D9-A4Z2                 5        Poor         2        50\nTCGA-EB-A3Y7                 4        Poor         1        86\nTCGA-DA-A1I7                 1        Good         2        62\nTCGA-DA-A1IA                 3        Good         1        32\n...                        ...         ...       ...       ...\nTCGA-FS-A1ZM                 3        Good         2        74\nTCGA-WE-A8ZR                 5        Poor         2        49\nTCGA-FS-A4FD                 3        Good         2        39\nTCGA-WE-A8K1                 4        Good         2        74\nTCGA-WE-A8ZO                 4        Good         1        73\n\n\nThis command reads in a preprocessed MultiAssayExperiment containing two assays: miRNA and mRNA. Pairwise ratios of gene expressions are used as predictive features. The miRNA assay contains 62 samples and 34351 features while the mRNA assay contains 62 samples and 14689 features.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Procedure 3: Multi-Platform Precision Pathway</span>"
    ]
  },
  {
    "objectID": "Procedure3.html#precision-pathways-and-evaluations",
    "href": "Procedure3.html#precision-pathways-and-evaluations",
    "title": "4  Procedure 3: Multi-Platform Precision Pathway",
    "section": "4.3 Precision pathways and evaluations",
    "text": "4.3 Precision pathways and evaluations\n3. Creating a prognostic precision pathway\nTiming ~ 260s\n\nset.seed(1)\npp &lt;- precisionPathwaysTrain(mel_mae, \"Outcome\")\npp &lt;- calcCostsAndPerformance(pp, setNames(c(0, 12400, 8000), c(\"Clinical\", \"RNA_pair\", \"miRNA_pair\")))\n\nThe set.seed(1) command ensures that any subsequent operations involving randomness yield consistent results across runs. The second command trains a multi-platform precision pathway using the two assays given the prognostic outcomes in the “Outcome” column in colData(mel_mae) Finally, the costs and performance of each potential pathway is calculated. Here, the cost of using clinical, mRNA and miRNA data have respectively been approximated to $0, $12400 and $8000.\n4. Precision Pathway Evaluation\nTiming ~ 1.4s\n\nsummary(pp)\n\n              Pathway Balanced Accuracy Total Cost Score\n1   clinical-RNA_pair              0.77     210800     1\n2 clinical-miRNA_pair              0.78     136000     2\n\n\nGiven the costs provided earlier in calcCostsAndPerformance, this command outputs the summary of performance and cost of each potential pathway for evaluation. There are two possible pathways proposed: using clinical then mRNA data or using clinical then miRNA data. Both pathways achieve the same balanced accuracy of 0.75 but due to the lower cost of miRNA sequencing, the second pathway attains a higher score and is the preferable option for prognostic purposes.\n\nbubblePlot(pp)\n\n\n\n\n\n\n\n\nThis bubble plot visualises the summary created above. In a situation with more potential pathways, it would allow greater ease in selecting the best pathway to optimise cost and performance. Here, clinical-miRNA would be the preferred pathway due to its lower cost while achieving the same balanced accuracy.\n\nflowchart(pp, \"clinical-miRNA_pair\")\n\n\n\n\n\nGiven that clinical-miRNA is the selected pathway, this function creates a flowchart to show the stepwise process for determining melanoma prognosis. Clinical data is first used to classify patients into three prognosis groups: • Good prognosis: 44% of patients (27 out of total 62). • Uncertain prognosis: 21% of patients (13 out of 62) • Poor prognosis: 35% of patients (22 out of 62). Thus, clinical data alone classifies 71% of patients (Good + Poor groups), while 21% requiring further assessment.\nFor the Uncertain prognosis group (13 patients), additional analysis using miRNA pair data refines the classification: • Good prognosis: 19% (12 patients) are identified as “Good.” • Uncertain prognosis: 0% (0 patients) remain “Uncertain.” • Poor prognosis: 2% (1 patient) is reclassified as “Poor.” This is why a potential pathway incorporating clinical, mRNA, and miRNA data was not considered, as the first two datasets alone provided a prognosis outcome for all individuals.\n\nstrataPlot(pp, \"clinical-miRNA_pair\")\n\n\n\n\n\n\n\n\nThis function creates a plot which allow us to visualise where the prognosis went wrong. A large amount of blue in the clinical row under the green, suggests that this pathway made the most errors in prognosis when first using clinical data, as it classified many “good” prognosis patients with “poor” prognosis. However, clinical data performed comparatively much better on “poor” prognosis patients due to the lesser proportion of blue. For the individuals who continued to use miRNA, there was high sensitivity in identifying individuals with a good prognosis but its specificity was limited as some individuals with a poor prognosis were misclassified as having a good prognosis.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Procedure 3: Multi-Platform Precision Pathway</span>"
    ]
  }
]