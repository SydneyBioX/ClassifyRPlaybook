[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ClassifyR PlayBook",
    "section": "",
    "text": "1 Overview",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#precision-medicine-and-the-need-for-advanced-classification-tools",
    "href": "index.html#precision-medicine-and-the-need-for-advanced-classification-tools",
    "title": "ClassifyR PlayBook",
    "section": "1.1 Precision medicine and the need for advanced classification tools",
    "text": "1.1 Precision medicine and the need for advanced classification tools\nPrecision medicine is a personalised approach to healthcare that tailors prevention, diagnosis, and treatment to an individual’s unique characteristics such as genetics, environment, lifestyle, and molecular data. By integrating diverse data types, the ultimate goal of precision medicine is to deliver the right decision or treatment to the right patient at the right time. While this has driven the development of complex classification strategies, realising this vision relies on robust evaluation of model performance at both cohort and patient levels. \n\n1.1.1 What is ClassifyR?\nThis playbook presents ClassifyR, a comprehensive machine learning framework tailored for multi-omics classification problems in a precision medicine context. ClassifyR was first introduced in 2015 as a tool for assessing classification performance in omics research, particularly evaluating feature selection approaches in transcriptomics (Strbenac et al., 2015). It provides systematic comparison of predictive models, emphasising accuracy, stability and interpretability. While machine learning evaluation frameworks such as caret and mlr in R and scikit-learn in Python provide general-purpose machine learning frameworks, they lack specific capabilities for pre-processing, feature selection, feature interrogation, multi-omic integration and cross-platform performance evaluation. Standardising these procedures into a unified framework can facilitate more systematic and robust evaluations. Thus, ClassifyR distinguishes itself in multiple ways:\n\nBioconductor ecosystem integration: ClassifyR is interoperable with established omics data structures in the Bioconductor Project, ensuring seamless access to single-cell, multi-omics, and spatial technologies.\nFull cross-validation workflow: The package performs comprehensive cross-validation by including feature selection and hyperparameter tuning within the cross-validation procedure, which is essential for handling large-scale omics datasets.\nCross-dataset and cross-modality validation: Models can be both constructed and evaluated across cohorts and omics platforms, addressing issues of reproducibility and transferability.\nPrecision medicine focus: ClassifyR includes frameworks for assessing model appropriateness at an individual patient level which is crucial for evaluating which model or modality is appropriate for which patient.\n\nBy addressing these critical gaps, ClassifyR enables researchers to explore complex disease mechanisms, optimise diagnostic workflows, and guide treatment strategies in precision medicine.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "Procedure1.html",
    "href": "Procedure1.html",
    "title": "2  Procedure 1",
    "section": "",
    "text": "2.1 Intro\nProcedure 1 aims to compare the classification sample accuracy of breast cancer subtypes using bulk gene expression data and histologically predicted gene expression data. Sample accuracy is defined as the proportion of correctly predicted classifications over multiple repeats. For example, if 70 out of 100 repeats correctly classify an individual, their sample accuracy is 0.70.\nThis analysis involves 54 oestrogen receptor-positive (ER+) and progesterone receptor-positive (PR+) breast cancer patients, with each assay containing expression values for 268 genes. The classification outcomes are ‘Subtype 1’ and ‘Subtype 2’, found by unsupervised machine learning. Subtype 1 corresponds to patients with higher expression of LPL, CAVIN2, and TIMP4 in macrophage cells, and ADIPOQ in stromal cells, associated with better survival. Subtype 2 is the opposite, associated with poorer survival. More details on the subtypes can be found at https://www.biorxiv.org/content/10.1101/2024.07.02.601790v1.full.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#set-up-the-environment-and-data-objects",
    "href": "Procedure1.html#set-up-the-environment-and-data-objects",
    "title": "2  Procedure 1",
    "section": "2.2 Set up the environment and data objects",
    "text": "2.2 Set up the environment and data objects\n1. Load the R packages into the R environment\nTiming ~ 6.5s\n\nlibrary(ClassifyR)\n\nClassifyR is used to perform all the demonstrated analyses.\n2. Import preprocessed datasets for analysis\nTiming ~ 0.04s\n\nghist_mae &lt;- readRDS(\"data/procedure1/ghist_multiassayexperiment.rds\")\n\nThis command reads in a MultiAssayExperiment with two assays. The first is bulk gene expression data for 54 breast cancer individuals and the second is bulk gene expression as predicted from histological images of the same individuals. They are respectively named bulk_gene_expression and histologically_predicted_gene_expression.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#cross-validated-classification",
    "href": "Procedure1.html#cross-validated-classification",
    "title": "2  Procedure 1",
    "section": "2.3 Cross-validated Classification",
    "text": "2.3 Cross-validated Classification\n3. Classifying patients into subtype outcomes\nTiming ~ 45.0s\n\nset.seed(1)\nclassifyr_result &lt;- crossValidate(ghist_mae, outcome = \"subtype\", nFolds = 5, nRepeats = 100, nCores = 5)\n\nThe set.seed(1) command ensures that any subsequent operations involving randomness yield consistent results across runs.\nThe next command uses the crossValidate function to perform 5-fold cross-validation with the automatically selected RandomForest classifier on both datasets. This process is repeated 100 times and utilizes 5 CPU cores for parallel processing to speed up classification. The type of classifier, number of folds, repeats and cores used can be adjusted as wished for different analyses. The outcome here is “subtype”, a column from colData(ghist_mae) containing the two breast cancer subtypes to be predicted.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#classification-evaluation",
    "href": "Procedure1.html#classification-evaluation",
    "title": "2  Procedure 1",
    "section": "2.4 Classification Evaluation",
    "text": "2.4 Classification Evaluation\n4. Visualising the classification performance\nTiming ~ 1.75s\n\nperformancePlot(classifyr_result)\n\n\n\n\n\n\n\n\nperformancePlot outputs a side-by-side boxplot of the balanced accuracies for each dataset.\nBoth methods perform comparably in terms of median balanced accuracy and also demonstrate similar distributions of performance as seen from the comparable interquartile range and range. There does not appear to be much difference in the classification performance of both assays.\n\nsamplesMetricMap(classifyr_result)\n\n\n\n\n\n\n\n\nTableGrob (2 x 1) \"arrange\": 2 grobs\n  z     cells    name                grob\n1 1 (2-2,1-1) arrange      gtable[layout]\n2 2 (1-1,1-1) arrange text[GRID.text.274]\n\n\nsamplesMetricMap outputs a heatmap showing the classification accuracy for each of 100 repeats in each sample. A greater proportion of samples show high sample accuracies (0.8,1] when classified by the expression data as opposed to the histological data.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1</span>"
    ]
  },
  {
    "objectID": "Procedure2.html",
    "href": "Procedure2.html",
    "title": "3  Procedure 2",
    "section": "",
    "text": "3.1 Intro\ntext",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procedure 2</span>"
    ]
  },
  {
    "objectID": "Procedure2.html#next-thing",
    "href": "Procedure2.html#next-thing",
    "title": "3  Procedure 2",
    "section": "3.2 Next thing",
    "text": "3.2 Next thing\nmore text",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procedure 2</span>"
    ]
  },
  {
    "objectID": "Procedure3.html",
    "href": "Procedure3.html",
    "title": "4  Procedure 3",
    "section": "",
    "text": "4.1 Intro\nProcedure 3 aims to construct a multi-platform precision pathway for determining the prognostic outcome of melanoma patients. This mimics a clinical diagnostic pathway, where given the results of a diagnostic test, a confident decision may be made, or the patient may be referred to collect more data from a different platform.\nFor this analysis, clinical data in addition to sequencing data from two platforms are employed for 62 samples and the data is accessible at Melanoma Explorer53. The first is an mRNA dataset assayed using Sentrix Human-6 v3 Expression BeadChips (Illumina, San Diego, CA). The second is a microRNA dataset with expression profiling performed using Agilent Technologies’ microRNA platform (version 16, Agilent Technologies, Santa Clara, CA). The prognosis outcome is classified as “Good” if survival is greater than 4 years from the date of tumor banking and “Poor” if survival is less than 1 year from the date of tumor banking. Patients who do not match a “Good” or “Poor” prognosis are excluded from analysis.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Procedure 3</span>"
    ]
  },
  {
    "objectID": "Procedure3.html#set-up-the-environment-and-data-objects",
    "href": "Procedure3.html#set-up-the-environment-and-data-objects",
    "title": "4  Procedure 3",
    "section": "4.2 Set up the environment and data objects",
    "text": "4.2 Set up the environment and data objects\n1. Load the R packages into the R environment\nTiming ~ 6.5s\n\nlibrary(ClassifyR)\n\nClassifyR is used to perform all the demonstrated analyses below.\n2. Import preprocessed datasets for analysis\nTiming ~ 0.82s\n\nmel_mae &lt;- readRDS(\"data/procedure3/MultiAssayExperiment.rds\")\ncolData(mel_mae)\n\nDataFrame with 62 rows and 4 columns\n             pathology_T_stage     Outcome       sex       age\n                     &lt;numeric&gt; &lt;character&gt; &lt;numeric&gt; &lt;integer&gt;\nTCGA-BF-A1PX                 5        Poor         2        56\nTCGA-D9-A4Z2                 5        Poor         2        50\nTCGA-EB-A3Y7                 4        Poor         1        86\nTCGA-DA-A1I7                 1        Good         2        62\nTCGA-DA-A1IA                 3        Good         1        32\n...                        ...         ...       ...       ...\nTCGA-FS-A1ZM                 3        Good         2        74\nTCGA-WE-A8ZR                 5        Poor         2        49\nTCGA-FS-A4FD                 3        Good         2        39\nTCGA-WE-A8K1                 4        Good         2        74\nTCGA-WE-A8ZO                 4        Good         1        73\n\n\nThis command reads in a preprocessed MultiAssayExperiment containing two assays: miRNA and mRNA. Pairwise ratios of gene expressions are used as predictive features. The miRNA assay contains 62 samples and 34351 features while the mRNA assay contains 62 samples and 14689 features.\n3. Creating a prognostic precision pathway\nTiming ~ 260s\n\nset.seed(1)\npp &lt;- precisionPathwaysTrain(mel_mae, \"Outcome\")\npp &lt;- calcCostsAndPerformance(pp, setNames(c(0, 12400, 8000), c(\"Clinical\", \"RNA_pair\", \"miRNA_pair\")))\n\nThe set.seed(1) command ensures that any subsequent operations involving randomness yield consistent results across runs. The second command trains a multi-platform precision pathway using the two assays given the prognostic outcomes in the “Outcome” column in colData(mel_mae) Finally, the costs and performance of each potential pathway is calculated. Here, the cost of using clinical, mRNA and miRNA data have respectively been approximated to $0, $12400 and $8000.\n4. Precision Pathway Evaluation\nTiming ~ 1.4s\n\nsummary(pp)\n\n              Pathway Balanced Accuracy Total Cost Score\n1   clinical-RNA_pair              0.77     210800     1\n2 clinical-miRNA_pair              0.78     136000     2\n\n\nGiven the costs provided earlier in calcCostsAndPerformance, this command outputs the summary of performance and cost of each potential pathway for evaluation. There are two possible pathways proposed: using clinical then mRNA data or using clinical then miRNA data. Both pathways achieve the same balanced accuracy of 0.75 but due to the lower cost of miRNA sequencing, the second pathway attains a higher score and is the preferable option for prognostic purposes.\n\nbubblePlot(pp)\n\n\n\n\n\n\n\n\nThis bubble plot visualises the summary created above. In a situation with more potential pathways, it would allow greater ease in selecting the best pathway to optimise cost and performance. Here, clinical-miRNA would be the preferred pathway due to its lower cost while achieving the same balanced accuracy.\n\nflow = flowchart(pp, \"clinical-miRNA_pair\")\n\nGiven that clinical-miRNA is the selected pathway, this function creates a flowchart to show the stepwise process for determining melanoma prognosis. Clinical data is first used to classify patients into three prognosis groups: • Good prognosis: 44% of patients (27 out of total 62). • Uncertain prognosis: 21% of patients (13 out of 62) • Poor prognosis: 35% of patients (22 out of 62). Thus, clinical data alone classifies 71% of patients (Good + Poor groups), while 21% requiring further assessment.\nFor the Uncertain prognosis group (13 patients), additional analysis using miRNA pair data refines the classification: • Good prognosis: 19% (12 patients) are identified as “Good.” • Uncertain prognosis: 0% (0 patients) remain “Uncertain.” • Poor prognosis: 2% (1 patient) is reclassified as “Poor.” This is why a potential pathway incorporating clinical, mRNA, and miRNA data was not considered, as the first two datasets alone provided a prognosis outcome for all individuals.\n\nstrataPlot(pp, \"clinical-miRNA_pair\")\n\n\n\n\n\n\n\n\nThis function creates a plot which allow us to visualise where the prognosis went wrong. A large amount of blue in the clinical row under the green, suggests that this pathway made the most errors in prognosis when first using clinical data, as it classified many “good” prognosis patients with “poor” prognosis. However, clinical data performed comparatively much better on “poor” prognosis patients due to the lesser proportion of blue. For the individuals who continued to use miRNA, there was high sensitivity in identifying individuals with a good prognosis but its specificity was limited as some individuals with a poor prognosis were misclassified as having a good prognosis.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Procedure 3</span>"
    ]
  },
  {
    "objectID": "Procedure4.html",
    "href": "Procedure4.html",
    "title": "5  Procedure 4",
    "section": "",
    "text": "5.1 Intro\nThe transferability of biomarkers from one patient population to another is often difficult to fully capture. Here we present three options for first assessing and then building transferable models from gene expression data.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Procedure 4</span>"
    ]
  },
  {
    "objectID": "Procedure4.html#intro",
    "href": "Procedure4.html#intro",
    "title": "5  Procedure 4",
    "section": "",
    "text": "5.1.1 Criss-cross validate\nLet’s suppose you want to assess how biomarkers selected from one population relate to another. In typical fashion you may build a model on one dataset through some cross-validation strategy and then attempt to predict the outcome of the paitent population in teh other cohort. This is of course rather procedural. Hence, criss-cross validate. A technique that performs a cross validation model building procedure on one dataset or group of patients and then applies this model to the other datasets you have collected. This procedure is repeated for n datasets.\nWe will use the recently published PROMAD database as a quick and easy way to collect",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Procedure 4</span>"
    ]
  },
  {
    "objectID": "Procedure4.html#next-thing",
    "href": "Procedure4.html#next-thing",
    "title": "5  Procedure 4",
    "section": "5.2 Next thing",
    "text": "5.2 Next thing\n\nlibrary(ClassifyR)\n\nLoading required package: generics\n\n\n\nAttaching package: 'generics'\n\n\nThe following objects are masked from 'package:base':\n\n    as.difftime, as.factor, as.ordered, intersect, is.element, setdiff,\n    setequal, union\n\n\nLoading required package: S4Vectors\n\n\nLoading required package: stats4\n\n\nLoading required package: BiocGenerics\n\n\n\nAttaching package: 'BiocGenerics'\n\n\nThe following objects are masked from 'package:generics':\n\n    intersect, setdiff, union\n\n\nThe following objects are masked from 'package:stats':\n\n    IQR, mad, sd, var, xtabs\n\n\nThe following objects are masked from 'package:base':\n\n    anyDuplicated, aperm, append, as.data.frame, basename, cbind,\n    colnames, dirname, do.call, duplicated, eval, evalq, Filter, Find,\n    get, grep, grepl, intersect, is.unsorted, lapply, Map, mapply,\n    match, mget, order, paste, pmax, pmax.int, pmin, pmin.int,\n    Position, rank, rbind, Reduce, rownames, sapply, saveRDS, setdiff,\n    table, tapply, union, unique, unsplit, which.max, which.min\n\n\n\nAttaching package: 'S4Vectors'\n\n\nThe following object is masked from 'package:utils':\n\n    findMatches\n\n\nThe following objects are masked from 'package:base':\n\n    expand.grid, I, unname\n\n\nLoading required package: MultiAssayExperiment\n\n\nLoading required package: SummarizedExperiment\n\n\nLoading required package: MatrixGenerics\n\n\nLoading required package: matrixStats\n\n\n\nAttaching package: 'MatrixGenerics'\n\n\nThe following objects are masked from 'package:matrixStats':\n\n    colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse,\n    colCounts, colCummaxs, colCummins, colCumprods, colCumsums,\n    colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs,\n    colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats,\n    colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds,\n    colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads,\n    colWeightedMeans, colWeightedMedians, colWeightedSds,\n    colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet,\n    rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods,\n    rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps,\n    rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins,\n    rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks,\n    rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars,\n    rowWeightedMads, rowWeightedMeans, rowWeightedMedians,\n    rowWeightedSds, rowWeightedVars\n\n\nLoading required package: GenomicRanges\n\n\nLoading required package: IRanges\n\n\nLoading required package: GenomeInfoDb\n\n\nLoading required package: Biobase\n\n\nWelcome to Bioconductor\n\n    Vignettes contain introductory material; view with\n    'browseVignettes()'. To cite Bioconductor, see\n    'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'.\n\n\n\nAttaching package: 'Biobase'\n\n\nThe following object is masked from 'package:MatrixGenerics':\n\n    rowMedians\n\n\nThe following objects are masked from 'package:matrixStats':\n\n    anyMissing, rowMedians\n\n\nLoading required package: BiocParallel\n\n\nLoading required package: survival\n\n\n\nAttaching package: 'ClassifyR'\n\n\nThe following object is masked from 'package:Biobase':\n\n    sampleNames\n\npromad_data &lt;- readRDS(\"data/procedure4/PROMAD_sample.Rds\")\nccv = crissCrossValidate(measurements = promad_data$measurements, \n                         outcome = promad_data$outcome,\n                         classifier = \"SVM\",\n                         nCores = 4)\n\nWarning in .local(measurements, ...): Unsafe feature names in input data.\nConverted into safe names.\nWarning in .local(measurements, ...): Unsafe feature names in input data.\nConverted into safe names.\nWarning in .local(measurements, ...): Unsafe feature names in input data.\nConverted into safe names.\nWarning in .local(measurements, ...): Unsafe feature names in input data.\nConverted into safe names.\n\ncrissCrossPlot(ccv)\n\n\n\n\n\n\n\nlibrary(TOP)\nData_temp = lapply(promad_data$measurements, \"[\", , TOP::filterFeatures(x_list = promad_data$measurements, \n                                                        y_list = promad_data$outcome, \n                                                        contrast = \"AR - Control\", \n                                                        nFeatures = 50))\n\nWarning in merge.data.frame(x, y, by = \"gene\", all = TRUE, no.dups = TRUE):\ncolumn names 't.x', 't.y' are duplicated in the result\n\ntopModel &lt;- TOP::TOP_model(x_list = Data_temp, y_list = promad_data$outcome)\n\nCalculating Pairwise Ratios of Features\n\n\nCalculating Fold Changes of Pairwise Ratios\n\n\nCalculating Final Weights\n\n\nFitting final lasso model\n\n\nmore text",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Procedure 4</span>"
    ]
  }
]