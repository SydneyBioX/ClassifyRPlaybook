[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ClassifyR PlayBook",
    "section": "",
    "text": "1 Overview",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#precision-medicine-and-the-need-for-advanced-classification-tools",
    "href": "index.html#precision-medicine-and-the-need-for-advanced-classification-tools",
    "title": "ClassifyR PlayBook",
    "section": "1.1 Precision medicine and the need for advanced classification tools",
    "text": "1.1 Precision medicine and the need for advanced classification tools\nPrecision medicine is a personalised approach to healthcare that tailors prevention, diagnosis, and treatment to an individual’s unique characteristics such as genetics, environment, lifestyle, and molecular data. By integrating diverse data types, the ultimate goal of precision medicine is to deliver the right decision or treatment to the right patient at the right time. While this has driven the development of complex classification strategies, realising this vision relies on robust evaluation of model performance at both cohort and patient levels. \n\n1.1.1 What is ClassifyR?\nThis playbook presents ClassifyR, a comprehensive machine learning framework tailored for multi-omics classification problems in a precision medicine context. ClassifyR was first introduced in 2015 as a tool for assessing classification performance in omics research, particularly evaluating feature selection approaches in transcriptomics (Strbenac et al., 2015). It provides systematic comparison of predictive models, emphasising accuracy, stability and interpretability. While machine learning evaluation frameworks such as caret and mlr in R and scikit-learn in Python provide general-purpose machine learning frameworks, they lack specific capabilities for pre-processing, feature selection, feature interrogation, multi-omic integration and cross-platform performance evaluation. Standardising these procedures into a unified framework can facilitate more systematic and robust evaluations. Thus, ClassifyR distinguishes itself in multiple ways:\n\nBioconductor ecosystem integration: ClassifyR is interoperable with established omics data structures in the Bioconductor Project, ensuring seamless access to single-cell, multi-omics, and spatial technologies.\nFull cross-validation workflow: The package performs comprehensive cross-validation by including feature selection and hyperparameter tuning within the cross-validation procedure, which is essential for handling large-scale omics datasets.\nCross-dataset and cross-modality validation: Models can be both constructed and evaluated across cohorts and omics platforms, addressing issues of reproducibility and transferability.\nPrecision medicine focus: ClassifyR includes frameworks for assessing model appropriateness at an individual patient level which is crucial for evaluating which model or modality is appropriate for which patient.\n\nBy addressing these critical gaps, ClassifyR enables researchers to explore complex disease mechanisms, optimise diagnostic workflows, and guide treatment strategies in precision medicine.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "Procedure1.html",
    "href": "Procedure1.html",
    "title": "2  Procedure 1: Comparing cross-validated results",
    "section": "",
    "text": "2.1 Introduction\nProcedure 1 aims to compare the sample accuracy of breast cancer subtype classification using bulk gene expression data and histologically predicted gene expression data. Sample accuracy is defined as the proportion of correctly predicted classifications over multiple repeats. For example, if 70 out of 100 repeats correctly classify an individual, their sample accuracy is 0.70.\nThis analysis involves 54 oestrogen receptor-positive (ER+) and progesterone receptor-positive (PR+) breast cancer patients, with each assay containing expression values for 268 genes. The classification outcomes are ‘Subtype 1’ and ‘Subtype 2’, found by unsupervised machine learning. Subtype 1 corresponds to patients with higher expression of LPL, CAVIN2, and TIMP4 in macrophage cells, and ADIPOQ in stromal cells, associated with better survival. Subtype 2 is the opposite, associated with poorer survival. More details on the subtypes can be found at https://www.biorxiv.org/content/10.1101/2024.07.02.601790v1.full.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1: Comparing cross-validated results</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#setting-up-the-environment-and-data-objects",
    "href": "Procedure1.html#setting-up-the-environment-and-data-objects",
    "title": "2  Procedure 1: Comparing cross-validated results",
    "section": "2.2 Setting up the environment and data objects",
    "text": "2.2 Setting up the environment and data objects\n1. Load the R packages into the R environment\nTiming ~ 6.5s\n\nlibrary(ClassifyR)\n\nClassifyR is used to perform all the demonstrated analyses.\n2. Import preprocessed datasets for analysis\nTiming ~ 0.04s\n\nghist_mae &lt;- readRDS(\"data/procedure1/ghist_multiassayexperiment.rds\")\n\nThis command reads in a MultiAssayExperiment with two assays. The first is bulk gene expression data for 54 breast cancer individuals and the second is bulk gene expression as predicted from histological images of the same individuals. They are respectively named bulk_gene_expression and histologically_predicted_gene_expression.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1: Comparing cross-validated results</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#cross-validated-classification",
    "href": "Procedure1.html#cross-validated-classification",
    "title": "2  Procedure 1: Comparing cross-validated results",
    "section": "2.3 Cross-validated Classification",
    "text": "2.3 Cross-validated Classification\n3. Classifying patients into subtype outcomes\nTiming ~ 45.0s\n\nset.seed(1)\nclassifyr_result &lt;- crossValidate(ghist_mae, outcome = \"subtype\", nFolds = 5, nRepeats = 100, nCores = 5)\n\nThe set.seed(1) command ensures that any subsequent operations involving randomness yield consistent results across runs.\nThe next command uses the crossValidate function to perform 5-fold cross-validation with the automatically selected RandomForest classifier on both datasets. This process is repeated 100 times and utilizes 5 CPU cores for parallel processing to speed up classification. The type of classifier, number of folds, repeats and cores used can be adjusted as wished for different analyses. The outcome here is “subtype”, a column from colData(ghist_mae) containing the two breast cancer subtypes to be predicted.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1: Comparing cross-validated results</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#classification-evaluation",
    "href": "Procedure1.html#classification-evaluation",
    "title": "2  Procedure 1: Comparing cross-validated results",
    "section": "2.4 Classification Evaluation",
    "text": "2.4 Classification Evaluation\n4. Visualising the classification performance\nTiming ~ 1.75s\n\nperformancePlot(classifyr_result)\n\n\n\n\n\n\n\n\nperformancePlot outputs a side-by-side boxplot of the balanced accuracies for each dataset.\nBoth methods perform comparably in terms of median balanced accuracy and also demonstrate similar distributions of performance as seen from the comparable interquartile range and range. There does not appear to be much difference in the classification performance of both assays.\n\nsamplesMetricMap(classifyr_result)\n\n\n\n\n\n\n\n\nTableGrob (2 x 1) \"arrange\": 2 grobs\n  z     cells    name                grob\n1 1 (2-2,1-1) arrange      gtable[layout]\n2 2 (1-1,1-1) arrange text[GRID.text.274]\n\n\nsamplesMetricMap outputs a heatmap showing the classification accuracy for each of 100 repeats in each sample. A greater proportion of samples show high sample accuracies (0.8,1] when classified by the expression data as opposed to the histological data.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1: Comparing cross-validated results</span>"
    ]
  },
  {
    "objectID": "Procedure2.html",
    "href": "Procedure2.html",
    "title": "3  Procedure 2: Multi-view classifiability evaluation",
    "section": "",
    "text": "3.1 Introduction\nProcedure 2 aims to investigate whether individual data views serve as the best predictors of breast cancer outcomes, or if integrating multiple views improve predictive accuracy. A view could be an omics assay or a particular metafeature generated from a particular data set.\nIn this analysis, the METABRIC breast cancer data set will be used for 165 samples with no detected lymph node metastasis. Different omics assays and pre-generated views will be utilised:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procedure 2: Multi-view classifiability evaluation</span>"
    ]
  },
  {
    "objectID": "Procedure2.html#introduction",
    "href": "Procedure2.html#introduction",
    "title": "3  Procedure 2: Multi-view classifiability evaluation",
    "section": "",
    "text": "Clinical: Contains the outcome of interest (recurrence-free survival) as well as covariates that could predict it, such as tumour size and grade.\nRNA abundance: This was measured by microarrays. Quantile normalisation and prove reannotation was made by cBioPortal. Top 2000 highly-variable genes are used for illustration.\nImaging mass cytometry: Complementary to RNA, this assay gives the protein abundances for a small panel of 39 proteins. This is the basis of:\n\nType Proportions: Using annotated cell types, the proportion of each cell type in each patient sample.\nType Protein Mean: For each cell type, the average abundance of each feature in each sample.\nType Pairs Colocated: For each pair of cell types, a score of association using their X and Y coordinates based on L curve.\nColocated in Regions: k-means clustering-based definition of regions and spatial association within them.\nProportion of Parent: Based on HOPACH hierarchical clustering, the proportion of a cell type to its parent type.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procedure 2: Multi-view classifiability evaluation</span>"
    ]
  },
  {
    "objectID": "Procedure2.html#setting-up-the-environment-and-data-objects",
    "href": "Procedure2.html#setting-up-the-environment-and-data-objects",
    "title": "3  Procedure 2: Multi-view classifiability evaluation",
    "section": "3.2 Setting up the environment and data objects",
    "text": "3.2 Setting up the environment and data objects\n1. Load the R packages into the R environment\nTiming ~ 6.6s\n\nlibrary(ClassifyR)\nlibrary(ggplot2)\n\nClassifyR is used to perform all the demonstrated analyses below.\n2. Import preprocessed datasets for analysis\nTiming ~ 0.055s\n\nMETABRIC &lt;- readRDS(\"data/procedure2/METABRICviews.rds\")\n\nThis command reads in the list of 7 preprocessed assays and views mentioned previously. They are named “clinical”, “RNA Microarray”, “Type Proportions”, “Type Protein Mean”, “Type Pairs Colocated”, “Colocated in Regions” and “Proportion of Parent”. They respectively contain 30, 2000, 22, 858, 484, 10 and 55 features for each of the 165 samples.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procedure 2: Multi-view classifiability evaluation</span>"
    ]
  },
  {
    "objectID": "Procedure2.html#model-building-and-evaluation",
    "href": "Procedure2.html#model-building-and-evaluation",
    "title": "3  Procedure 2: Multi-view classifiability evaluation",
    "section": "3.3 Model Building and Evaluation",
    "text": "3.3 Model Building and Evaluation\nHere, models will be built by 3 different methods of assay and view integrations: step 3 - individual assays, step 4 - merging assays and step 5 - prevalidation.\n3. Individual Assays\nTiming ~ 82s\n\nset.seed(1)\nusefulFeatures &lt;- c(\"Breast.Tumour.Laterality\", \"ER.Status\", \"Inferred.Menopausal.State\",\n                    \"Grade\", \"Size\", \"Stage\")\ncoxPredicts &lt;- crossValidate(METABRIC, c(\"timeRFS\", \"eventRFS\"),\n                             selectionMethod = \"CoxPH\", classifier = \"CoxNet\", nCores = 20,\n                             extraParams = list(prepare = list(useFeatures = list(clinical = usefulFeatures))))\n\nThe set.seed(1) command ensures that any subsequent operations involving randomness yield consistent results across runs.\nThe next command selects only the biologically relevant features in the clinical data to be used later for model building, as there are arbitrary sample identifiers, dates and other non-biological information which should not be used\nThe crossValidate function is then used to perform 5-fold cross-validation for 20 repeats, fitting a penalised Cox proportional hazards model to each assay individually. 20 CPU cores are used for parallel processing to speed up classification. The type of classifier, number of folds, repeats and cores used can be adjusted as wished for different analyses. The outcomes here are timeRFS and eventRFS, 2 columns from METABRIC[[\"clinical\"]].\nTiming ~ 1.5s\n\nperformancePlot(coxPredicts, orderingList = list(\"Assay Name\" = \"performanceDescending\")) +\n    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))\n\nWarning in .local(results, ...): C-index not found in all elements of results.\nCalculating it now.\n\n\n\n\n\n\n\n\n\nThis command generates a side-by-side boxplot of C-index for each individual assay by performancePlot to compare their classification performance. The most accurate view is Proportion of Parent, but interestingly, using just the freely available clinical data attains a similar performance. Further, the protein assay views also performed surprisingly well despite having about a hundred times less features to use than RNA does.\nTiming ~ 22s\n\nsamplesMetricMap(coxPredicts, showXtickLabels = FALSE)\n\nWarning in .local(results, ...): Sample C-index not found in all elements of\nresults. Calculating it now.\n\n\n\n\n\n\n\n\n\nTableGrob (2 x 1) \"arrange\": 2 grobs\n  z     cells    name                grob\n1 1 (2-2,1-1) arrange      gtable[layout]\n2 2 (1-1,1-1) arrange text[GRID.text.257]\n\n\n4. Merged Assays\nTiming ~ 29mins\nNote: Type Protein Mean and Type Proportions have been removed for the following analysis to save run time.\n\nset.seed(1)\nmerge &lt;- c(\"clinical\", \"Colocated in Regions\", \"Proportion of Parent\", \"Type Pairs Colocated\", \"RNA Microarray\")\ncoxMergePredicts &lt;- crossValidate(METABRIC[merge], c(\"timeRFS\", \"eventRFS\"), multiViewMethod = \"merge\", extraParams = list(prepare = list(useFeatures = list(clinical = usefulFeatures))), selectionMethod = \"CoxPH\", classifier = \"CoxNet\", nCores = 20)\n\nperformancePlot(coxMergePredicts, orderingList = list(\"Assay Name\" = \"performanceDescending\"))\n\n\n\n\n\n\n\n\nThe 3 commands used here are the same as for individual assays in step 3, with the only difference being the merge combination method used for the multiViewMethod argument in the second command to concatenate the independently selected features in each view. Other multiVewMethods include prevalidation and PCA. The produced plot suggests that combining clinical data with imaging mass cytometry views can improve performance. Specifically, the best performing combination used clinical, Colocated in Regions and Type Pairs Colocated to achieve a C-index which surpasses Proportion of Parent, the best performing individual assay. Hence, integrating multiple views have successfully improved prediction accuracy.\nTiming ~ 95s\n\nsamplesMetricMap(coxMergePredicts, showXtickLabels = FALSE)\n\nWarning in .local(results, ...): Sample C-index not found in all elements of\nresults. Calculating it now.\n\n\n\n\n\n\n\n\n\nTableGrob (2 x 1) \"arrange\": 2 grobs\n  z     cells    name                grob\n1 1 (2-2,1-1) arrange      gtable[layout]\n2 2 (1-1,1-1) arrange text[GRID.text.755]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procedure 2: Multi-view classifiability evaluation</span>"
    ]
  },
  {
    "objectID": "Procedure3.html",
    "href": "Procedure3.html",
    "title": "4  Procedure 3: Multi-Platform Precision Pathway",
    "section": "",
    "text": "4.1 Introduction\nProcedure 3 aims to construct a multi-platform precision pathway for determining the prognostic outcome of melanoma patients. This mimics a clinical diagnostic pathway, where given the results of a diagnostic test, a confident decision may be made, or the patient may be referred to collect more data from a different platform.\nFor this analysis, clinical data in addition to sequencing data from two platforms are employed for 62 samples and the data is accessible at Melanoma Explorer53. The first is an mRNA dataset assayed using Sentrix Human-6 v3 Expression BeadChips (Illumina, San Diego, CA). The second is a microRNA dataset with expression profiling performed using Agilent Technologies’ microRNA platform (version 16, Agilent Technologies, Santa Clara, CA). The prognosis outcome is classified as “Good” if survival is greater than 4 years from the date of tumor banking and “Poor” if survival is less than 1 year from the date of tumor banking. Patients who do not match a “Good” or “Poor” prognosis are excluded from analysis.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Procedure 3: Multi-Platform Precision Pathway</span>"
    ]
  },
  {
    "objectID": "Procedure3.html#setting-up-the-environment-and-data-objects",
    "href": "Procedure3.html#setting-up-the-environment-and-data-objects",
    "title": "4  Procedure 3: Multi-Platform Precision Pathway",
    "section": "4.2 Setting up the environment and data objects",
    "text": "4.2 Setting up the environment and data objects\n1. Load the R packages into the R environment\nTiming ~ 6.5s\n\nlibrary(ClassifyR)\n\nClassifyR is used to perform all the demonstrated analyses below.\n2. Import preprocessed datasets for analysis\nTiming ~ 0.82s\n\nmel_mae &lt;- readRDS(\"data/procedure3/MultiAssayExperiment.rds\")\ncolData(mel_mae)\n\nDataFrame with 62 rows and 4 columns\n             pathology_T_stage     Outcome       sex       age\n                     &lt;numeric&gt; &lt;character&gt; &lt;numeric&gt; &lt;integer&gt;\nTCGA-BF-A1PX                 5        Poor         2        56\nTCGA-D9-A4Z2                 5        Poor         2        50\nTCGA-EB-A3Y7                 4        Poor         1        86\nTCGA-DA-A1I7                 1        Good         2        62\nTCGA-DA-A1IA                 3        Good         1        32\n...                        ...         ...       ...       ...\nTCGA-FS-A1ZM                 3        Good         2        74\nTCGA-WE-A8ZR                 5        Poor         2        49\nTCGA-FS-A4FD                 3        Good         2        39\nTCGA-WE-A8K1                 4        Good         2        74\nTCGA-WE-A8ZO                 4        Good         1        73\n\n\nThis command reads in a preprocessed MultiAssayExperiment containing two assays: miRNA and mRNA. Pairwise ratios of gene expressions are used as predictive features. The miRNA assay contains 62 samples and 34351 features while the mRNA assay contains 62 samples and 14689 features.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Procedure 3: Multi-Platform Precision Pathway</span>"
    ]
  },
  {
    "objectID": "Procedure3.html#precision-pathways-and-evaluations",
    "href": "Procedure3.html#precision-pathways-and-evaluations",
    "title": "4  Procedure 3: Multi-Platform Precision Pathway",
    "section": "4.3 Precision pathways and evaluations",
    "text": "4.3 Precision pathways and evaluations\n3. Creating a prognostic precision pathway\nTiming ~ 260s\n\nset.seed(1)\npp &lt;- precisionPathwaysTrain(mel_mae, \"Outcome\")\npp &lt;- calcCostsAndPerformance(pp, setNames(c(0, 12400, 8000), c(\"Clinical\", \"RNA_pair\", \"miRNA_pair\")))\n\nThe set.seed(1) command ensures that any subsequent operations involving randomness yield consistent results across runs. The second command trains a multi-platform precision pathway using the two assays given the prognostic outcomes in the “Outcome” column in colData(mel_mae) Finally, the costs and performance of each potential pathway is calculated. Here, the cost of using clinical, mRNA and miRNA data have respectively been approximated to $0, $12400 and $8000.\n4. Precision Pathway Evaluation\nTiming ~ 1.4s\n\nsummary(pp)\n\n              Pathway Balanced Accuracy Total Cost Score\n1   clinical-RNA_pair              0.77     210800     1\n2 clinical-miRNA_pair              0.78     136000     2\n\n\nGiven the costs provided earlier in calcCostsAndPerformance, this command outputs the summary of performance and cost of each potential pathway for evaluation. There are two possible pathways proposed: using clinical then mRNA data or using clinical then miRNA data. Both pathways achieve the same balanced accuracy of 0.75 but due to the lower cost of miRNA sequencing, the second pathway attains a higher score and is the preferable option for prognostic purposes.\n\nbubblePlot(pp)\n\n\n\n\n\n\n\n\nThis bubble plot visualises the summary created above. In a situation with more potential pathways, it would allow greater ease in selecting the best pathway to optimise cost and performance. Here, clinical-miRNA would be the preferred pathway due to its lower cost while achieving the same balanced accuracy.\n\nflowchart(pp, \"clinical-miRNA_pair\")\n\n\n\n\n\nGiven that clinical-miRNA is the selected pathway, this function creates a flowchart to show the stepwise process for determining melanoma prognosis. Clinical data is first used to classify patients into three prognosis groups: • Good prognosis: 44% of patients (27 out of total 62). • Uncertain prognosis: 21% of patients (13 out of 62) • Poor prognosis: 35% of patients (22 out of 62). Thus, clinical data alone classifies 71% of patients (Good + Poor groups), while 21% requiring further assessment.\nFor the Uncertain prognosis group (13 patients), additional analysis using miRNA pair data refines the classification: • Good prognosis: 19% (12 patients) are identified as “Good.” • Uncertain prognosis: 0% (0 patients) remain “Uncertain.” • Poor prognosis: 2% (1 patient) is reclassified as “Poor.” This is why a potential pathway incorporating clinical, mRNA, and miRNA data was not considered, as the first two datasets alone provided a prognosis outcome for all individuals.\n\nstrataPlot(pp, \"clinical-miRNA_pair\")\n\n\n\n\n\n\n\n\nThis function creates a plot which allow us to visualise where the prognosis went wrong. A large amount of blue in the clinical row under the green, suggests that this pathway made the most errors in prognosis when first using clinical data, as it classified many “good” prognosis patients with “poor” prognosis. However, clinical data performed comparatively much better on “poor” prognosis patients due to the lesser proportion of blue. For the individuals who continued to use miRNA, there was high sensitivity in identifying individuals with a good prognosis but its specificity was limited as some individuals with a poor prognosis were misclassified as having a good prognosis.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Procedure 3: Multi-Platform Precision Pathway</span>"
    ]
  }
]