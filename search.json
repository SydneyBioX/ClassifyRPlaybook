[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ClassifyR PlayBook",
    "section": "",
    "text": "1 Overview",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#precision-medicine-and-the-need-for-advanced-classification-tools",
    "href": "index.html#precision-medicine-and-the-need-for-advanced-classification-tools",
    "title": "ClassifyR PlayBook",
    "section": "1.1 Precision medicine and the need for advanced classification tools",
    "text": "1.1 Precision medicine and the need for advanced classification tools\nPrecision medicine is a personalised approach to healthcare that tailors prevention, diagnosis, and treatment to an individual’s unique characteristics such as genetics, environment, lifestyle, and molecular data. By integrating diverse data types, the ultimate goal of precision medicine is to deliver the right decision or treatment to the right patient at the right time. While this has driven the development of complex classification strategies, realising this vision relies on robust evaluation of model performance at both cohort and patient levels. \n\n1.1.1 What is ClassifyR?\nThis playbook presents ClassifyR, a comprehensive machine learning framework tailored for multi-omics classification problems in a precision medicine context. ClassifyR was first introduced in 2015 as a tool for assessing classification performance in omics research, particularly evaluating feature selection approaches in transcriptomics (Strbenac et al., 2015). It provides systematic comparison of predictive models, emphasising accuracy, stability and interpretability. While machine learning evaluation frameworks such as caret and mlr in R and scikit-learn in Python provide general-purpose machine learning frameworks, they lack specific capabilities for pre-processing, feature selection, feature interrogation, multi-omic integration and cross-platform performance evaluation. Standardising these procedures into a unified framework can facilitate more systematic and robust evaluations. Thus, ClassifyR distinguishes itself in multiple ways:\n\nBioconductor ecosystem integration: ClassifyR is interoperable with established omics data structures in the Bioconductor Project, ensuring seamless access to single-cell, multi-omics, and spatial technologies.\nFull cross-validation workflow: The package performs comprehensive cross-validation by including feature selection and hyperparameter tuning within the cross-validation procedure, which is essential for handling large-scale omics datasets.\nCross-dataset and cross-modality validation: Models can be both constructed and evaluated across cohorts and omics platforms, addressing issues of reproducibility and transferability.\nPrecision medicine focus: ClassifyR includes frameworks for assessing model appropriateness at an individual patient level which is crucial for evaluating which model or modality is appropriate for which patient.\n\nBy addressing these critical gaps, ClassifyR enables researchers to explore complex disease mechanisms, optimise diagnostic workflows, and guide treatment strategies in precision medicine.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "Procedure1.html",
    "href": "Procedure1.html",
    "title": "2  Procedure 1: Comparing cross-validated results",
    "section": "",
    "text": "2.1 Introduction\nProcedure 1 aims to compare the sample accuracy of breast cancer subtype classification using bulk gene expression data and histologically predicted gene expression data. Sample accuracy is defined as the proportion of correctly predicted classifications over multiple repeats. For example, if 70 out of 100 repeats correctly classify an individual, their sample accuracy is 0.70.\nThis analysis involves 54 oestrogen receptor-positive (ER+) and progesterone receptor-positive (PR+) breast cancer patients, with each assay containing expression values for 268 genes. The classification outcomes are ‘Subtype 1’ and ‘Subtype 2’, found by unsupervised machine learning. Subtype 1 corresponds to patients with higher expression of LPL, CAVIN2, and TIMP4 in macrophage cells, and ADIPOQ in stromal cells, associated with better survival. Subtype 2 is the opposite, associated with poorer survival. More details on the subtypes can be found at https://www.biorxiv.org/content/10.1101/2024.07.02.601790v1.full.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1: Comparing cross-validated results</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#setting-up-the-environment-and-data-objects",
    "href": "Procedure1.html#setting-up-the-environment-and-data-objects",
    "title": "2  Procedure 1: Comparing cross-validated results",
    "section": "2.2 Setting up the environment and data objects",
    "text": "2.2 Setting up the environment and data objects\n1. Load the R packages into the R environment\nTiming ~ 6.5s\n\nlibrary(ClassifyR)\n\nClassifyR is used to perform all the demonstrated analyses.\n2. Import preprocessed datasets for analysis\nTiming ~ 0.04s\n\nghistMAE &lt;- readRDS(\"data/procedure1/ghist_multiassayexperiment.rds\")\n\nThis command reads in a MultiAssayExperiment with two assays. The first is bulk gene expression data for 54 breast cancer individuals and the second is bulk gene expression as predicted from histological images of the same individuals. They are respectively named gene_expression and histology_inferred.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1: Comparing cross-validated results</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#cross-validated-classification",
    "href": "Procedure1.html#cross-validated-classification",
    "title": "2  Procedure 1: Comparing cross-validated results",
    "section": "2.3 Cross-validated Classification",
    "text": "2.3 Cross-validated Classification\n3. Classifying patients into subtype outcomes\nTiming ~ 45.0s\n\nset.seed(1)\nclassifyResult &lt;- crossValidate(ghistMAE, outcome = \"subtype\", nFolds = 5, nRepeats = 100, nCores = 8)\n\nThe set.seed(1) command ensures that any subsequent operations involving randomness yield consistent results across runs.\nThe next command uses the crossValidate function to perform 5-fold cross-validation with the automatically selected RandomForest classifier on both datasets. This process is repeated 100 times and utilizes 5 CPU cores for parallel processing to speed up classification. The type of classifier, number of folds, repeats and cores used can be adjusted as wished for different analyses. The outcome here is “subtype”, a column from colData(ghist_mae) containing the two breast cancer subtypes to be predicted.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1: Comparing cross-validated results</span>"
    ]
  },
  {
    "objectID": "Procedure1.html#classification-evaluation",
    "href": "Procedure1.html#classification-evaluation",
    "title": "2  Procedure 1: Comparing cross-validated results",
    "section": "2.4 Classification Evaluation",
    "text": "2.4 Classification Evaluation\n4. Visualising the classification performance\nTiming ~ 1.75s\n\nperformancePlot(classifyResult)\n\n\n\n\n\n\n\n\n\n\npng \n  2 \n\n\nperformancePlot outputs a side-by-side boxplot of the balanced accuracies for each dataset.\nBoth methods perform comparably in terms of median balanced accuracy and also demonstrate similar distributions of performance as seen from the comparable interquartile range and range. There does not appear to be much difference in the classification performance of both assays.\n\nsamplesMetricMap(classifyResult, showXtickLabels = FALSE)\n\n\n\n\n\n\n\n\nTableGrob (2 x 1) \"arrange\": 2 grobs\n  z     cells    name                grob\n1 1 (2-2,1-1) arrange      gtable[layout]\n2 2 (1-1,1-1) arrange text[GRID.text.347]\n\n\n\n\nTableGrob (2 x 1) \"arrange\": 2 grobs\n  z     cells    name                grob\n1 1 (2-2,1-1) arrange      gtable[layout]\n2 2 (1-1,1-1) arrange text[GRID.text.550]\n\n\npng \n  2 \n\n\nsamplesMetricMap outputs a heatmap showing the classification accuracy for each of 100 repeats in each sample. A greater proportion of samples show high sample accuracies (0.8,1] when classified by the expression data as opposed to the histological data.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Procedure 1: Comparing cross-validated results</span>"
    ]
  },
  {
    "objectID": "Procedure2.html",
    "href": "Procedure2.html",
    "title": "3  Procedure 2: Multi-view classifiability evaluation",
    "section": "",
    "text": "3.1 Introduction\nProcedure 2 aims to investigate whether individual data views serve as the best predictors of breast cancer outcomes, or if integrating multiple views improve predictive accuracy. A view could be an omics assay or a particular metafeature generated from a particular data set.\nIn this analysis, the METABRIC breast cancer data set will be used for 165 samples with no detected lymph node metastasis. Different omics assays and pre-generated views will be utilised:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procedure 2: Multi-view classifiability evaluation</span>"
    ]
  },
  {
    "objectID": "Procedure2.html#introduction",
    "href": "Procedure2.html#introduction",
    "title": "3  Procedure 2: Multi-view classifiability evaluation",
    "section": "",
    "text": "Clinical: Contains the outcome of interest (recurrence-free survival) as well as covariates that could predict it, such as tumour size and grade.\nRNA abundance: This was measured by microarrays. Quantile normalisation and prove reannotation was made by cBioPortal. Top 2000 highly-variable genes are used for illustration.\nImaging mass cytometry: Complementary to RNA, this assay gives the protein abundances for a small panel of 39 proteins. This is the basis of:\n\nType Proportions: Using annotated cell types, the proportion of each cell type in each patient sample.\nType Protein Mean: For each cell type, the average abundance of each feature in each sample.\nType Pairs Colocated: For each pair of cell types, a score of association using their X and Y coordinates based on L curve.\nColocated in Regions: k-means clustering-based definition of regions and spatial association within them.\nProportion of Parent: Based on HOPACH hierarchical clustering, the proportion of a cell type to its parent type.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procedure 2: Multi-view classifiability evaluation</span>"
    ]
  },
  {
    "objectID": "Procedure2.html#setting-up-the-environment-and-data-objects",
    "href": "Procedure2.html#setting-up-the-environment-and-data-objects",
    "title": "3  Procedure 2: Multi-view classifiability evaluation",
    "section": "3.2 Setting up the environment and data objects",
    "text": "3.2 Setting up the environment and data objects\n1. Load the R packages into the R environment\nTiming ~ 6.6s\n\nlibrary(ClassifyR)\nlibrary(ggplot2)\n\nClassifyR is used to perform all the demonstrated analyses below.\n2. Import preprocessed datasets for analysis\nTiming ~ 0.055s\n\nMETABRIC &lt;- readRDS(\"data/procedure2/METABRICviews.rds\")\n\nThis command reads in the list of 7 preprocessed assays and views mentioned previously. They are named “clinical”, “RNA Microarray”, “Type Proportions”, “Type Protein Mean”, “Type Pairs Colocated”, “Colocated in Regions” and “Proportion of Parent”. They respectively contain 30, 2000, 22, 858, 484, 10 and 55 features for each of the 165 samples.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procedure 2: Multi-view classifiability evaluation</span>"
    ]
  },
  {
    "objectID": "Procedure2.html#model-building-and-evaluation",
    "href": "Procedure2.html#model-building-and-evaluation",
    "title": "3  Procedure 2: Multi-view classifiability evaluation",
    "section": "3.3 Model Building and Evaluation",
    "text": "3.3 Model Building and Evaluation\nHere, models will be built by 3 different methods of assay and view integrations: step 3 - individual assays, step 4 - merging assays and step 5 - prevalidation.\n3. Individual Assays\nTiming ~ 82s\n\nset.seed(1)\nusefulFeatures &lt;- c(\"Breast.Tumour.Laterality\", \"ER.Status\", \"Inferred.Menopausal.State\",\n                    \"Grade\", \"Size\", \"Stage\")\ncoxCV &lt;- crossValidate(METABRIC, c(\"timeRFS\", \"eventRFS\"), selectionMethod = \"CoxPH\", classifier = \"CoxNet\",\n                       nCores = 8, extraParams = list(prepare = list(useFeatures = list(clinical = usefulFeatures))))\n\nThe set.seed(1) command ensures that any subsequent operations involving randomness yield consistent results across runs.\nThe next command selects only the biologically relevant features in the clinical data to be used later for model building, as there are arbitrary sample identifiers, dates and other non-biological information which should not be used\nThe crossValidate function is then used to perform 5-fold cross-validation for 20 repeats, fitting a penalised Cox proportional hazards model to each assay individually. 20 CPU cores are used for parallel processing to speed up classification. The type of classifier, number of folds, repeats and cores used can be adjusted as wished for different analyses. The outcomes here are timeRFS and eventRFS, 2 columns from METABRIC[[\"clinical\"]].\nTiming ~ 1.5s\n\nperformancePlot(coxCV, orderingList = list(\"Assay Name\" = \"performanceDescending\")) +\n    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))\n\nWarning in .local(results, ...): C-index not found in all elements of results.\nCalculating it now.\n\n\n\n\n\n\n\n\n\n\n\npng \n  2 \n\n\nThis command generates a side-by-side boxplot of C-index for each individual assay by performancePlot to compare their classification performance. The most accurate view is Proportion of Parent, but interestingly, using just the freely available clinical data attains a similar performance. Further, the protein assay views also performed surprisingly well despite having about a hundred times less features to use than RNA does.\nTiming ~ 22s\n\nsamplesMetricMap(coxCV, showXtickLabels = FALSE)\n\nWarning in .local(results, ...): Sample C-index not found in all elements of\nresults. Calculating it now.\n\n\n\n\n\n\n\n\n\nTableGrob (2 x 1) \"arrange\": 2 grobs\n  z     cells    name                grob\n1 1 (2-2,1-1) arrange      gtable[layout]\n2 2 (1-1,1-1) arrange text[GRID.text.354]\n\n\n\n\nTableGrob (2 x 1) \"arrange\": 2 grobs\n  z     cells    name                grob\n1 1 (2-2,1-1) arrange      gtable[layout]\n2 2 (1-1,1-1) arrange text[GRID.text.508]\n\n\npng \n  2 \n\n\n4. Merged Assays\nTiming ~ 29mins\nNote: Type Protein Mean and Type Proportions have been removed for the following analysis to save run time.\n\nset.seed(1)\nxOrder &lt;- list(\"Assay Name\" = \"performanceDescending\")\nmerge &lt;- c(\"clinical\", \"Domain Proportions\", \"Proportions of Parent\", \"Colocalisation\", \"RNA Microarray\")\ncoxMergeCV &lt;- crossValidate(METABRIC[merge], c(\"timeRFS\", \"eventRFS\"), multiViewMethod = \"merge\", extraParams = list(prepare = list(useFeatures = list(clinical = usefulFeatures))), selectionMethod = \"CoxPH\", classifier = \"CoxNet\", nCores = 8)\n\nperformancePlot(coxMergeCV, orderingList = list(\"Assay Name\" = \"performanceDescending\"))\n\n\n\n\n\n\n\n\n\n\npng \n  2 \n\n\nThe 3 commands used here are the same as for individual assays in step 3, with the only difference being the merge combination method used for the multiViewMethod argument in the second command to concatenate the independently selected features in each view. Other multiVewMethods include prevalidation and PCA. The produced plot suggests that combining clinical data with imaging mass cytometry views can improve performance. Specifically, the best performing combination used clinical, Colocated in Regions and Type Pairs Colocated to achieve a C-index which surpasses Proportion of Parent, the best performing individual assay. Hence, integrating multiple views have successfully improved prediction accuracy.\nTiming ~ 95s\n\nsamplesMetricMap(coxMergeCV, showXtickLabels = FALSE)\n\nWarning in .local(results, ...): Sample C-index not found in all elements of\nresults. Calculating it now.\n\n\n\n\n\n\n\n\n\nTableGrob (2 x 1) \"arrange\": 2 grobs\n  z     cells    name                 grob\n1 1 (2-2,1-1) arrange       gtable[layout]\n2 2 (1-1,1-1) arrange text[GRID.text.1354]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procedure 2: Multi-view classifiability evaluation</span>"
    ]
  },
  {
    "objectID": "Procedure3.html",
    "href": "Procedure3.html",
    "title": "4  Procedure 3: Multi-Platform Precision Pathway",
    "section": "",
    "text": "4.1 Introduction\nProcedure 3 aims to construct a multi-platform precision pathway for determining the prognostic outcome of melanoma patients. This mimics a clinical diagnostic pathway, where given the results of a diagnostic test, a confident decision may be made, or the patient may be referred to collect more data from a different platform.\nFor this analysis, two cohorts are used. Both have clinical data, and miRNA and mRNA omics data.\nThe prognosis outcome is classified as “Good” if survival is greater than 4 years from the date of tumor banking and “Poor” if survival is less than 1 year from the date of tumor banking. Patients who do not match a “Good” or “Poor” prognosis are excluded from analysis.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Procedure 3: Multi-Platform Precision Pathway</span>"
    ]
  },
  {
    "objectID": "Procedure3.html#introduction",
    "href": "Procedure3.html#introduction",
    "title": "4  Procedure 3: Multi-Platform Precision Pathway",
    "section": "",
    "text": "The Cancer Genome Atlas (T.C.G.A.): 62 patients. Both omics modalities use high-throughput sequencing.\nMelanoma Institute of Australia (M.I.A.): 42 patients. Both omics modalities use probe-based microarrays.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Procedure 3: Multi-Platform Precision Pathway</span>"
    ]
  },
  {
    "objectID": "Procedure3.html#setting-up-the-environment-and-data-objects",
    "href": "Procedure3.html#setting-up-the-environment-and-data-objects",
    "title": "4  Procedure 3: Multi-Platform Precision Pathway",
    "section": "4.2 Setting up the environment and data objects",
    "text": "4.2 Setting up the environment and data objects\n1. Load the R packages into the R environment\nTiming ~ 6.5s\n\nlibrary(ClassifyR)\n\nClassifyR is used to perform all the demonstrated analyses below.\n2. Import preprocessed datasets for analysis\nTiming ~ 1s\n\nmelanomaTCGA &lt;- readRDS(\"data/procedure3/TCGAmRNAandMicroRNA.rds\")\nmelanomaMIA &lt;- readRDS(\"data/procedure3/MIAmRNAandMicroRNA.rds\")\ncolData(melanomaTCGA)\n\nDataFrame with 62 rows and 4 columns\n              Outcome      Sex       Age    Tstage\n             &lt;factor&gt; &lt;factor&gt; &lt;integer&gt; &lt;numeric&gt;\nTCGA-BF-A1PX     Poor   Male          56         4\nTCGA-D9-A4Z2     Poor   Male          50         4\nTCGA-EB-A3Y7     Poor   Female        86         3\nTCGA-DA-A1I7     Good   Male          62         0\nTCGA-DA-A1IA     Good   Female        32         2\n...               ...      ...       ...       ...\nTCGA-FS-A1ZM     Good   Male          74         2\nTCGA-WE-A8ZR     Poor   Male          49         4\nTCGA-FS-A4FD     Good   Male          39         2\nTCGA-WE-A8K1     Good   Male          74         3\nTCGA-WE-A8ZO     Good   Female        73         3\n\ncolData(melanomaMIA)\n\nDataFrame with 42 rows and 4 columns\n     Outcome      Sex       Age    Tstage\n    &lt;factor&gt; &lt;factor&gt; &lt;numeric&gt; &lt;numeric&gt;\n172     Good   Female        84         2\n249     Good   Female        67         2\n288     Good   Male          54         2\n36      Poor   Female        70         2\n1       Poor   Female        75         4\n...      ...      ...       ...       ...\n350     Good   Male          80         4\n334     Poor   Female        58         3\n340     Poor   Male          76         1\n333     Good   Male          59         3\n351     Poor   Male          64         1\n\n\nThese commands read in a preprocessed MultiAssayExperiment containing two assays: miRNA and mRNA. Pairwise ratios of gene expression are used as predictive features. Patient age is at time of diagnosis and in years.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Procedure 3: Multi-Platform Precision Pathway</span>"
    ]
  },
  {
    "objectID": "Procedure3.html#precision-pathways-and-evaluations",
    "href": "Procedure3.html#precision-pathways-and-evaluations",
    "title": "4  Procedure 3: Multi-Platform Precision Pathway",
    "section": "4.3 Precision pathways and evaluations",
    "text": "4.3 Precision pathways and evaluations\n3. Creating a prognostic precision pathway\nTiming ~ 260s\n\nset.seed(2025)\npathways &lt;- precisionPathwaysTrain(melanomaTCGA, \"Outcome\", mode = \"combinatorial\", nCores = 8)\n\nThe set.seed(1) command ensures that any subsequent operations involving randomness yield consistent results across runs. The second command trains multi-platform precision pathways using the two assays given the prognostic outcomes in the “Outcome” column in colData(melanomaTCGA).\n\ncosts &lt;- setNames(c(50, 400, 700), c(\"clinical\", \"miRNA\", \"RNA\"))\npredicted &lt;- precisionPathwaysPredict(pathways, melanomaMIA, \"Outcome\")\npredicted &lt;- calcCostsAndPerformance(predicted, costs)\n\nNow, the constructed pathways are applied to M.I.A. dataset. Finally, the costs and performance of each potential pathway is calculated. Here, the cost of using clinical, mRNA and miRNA data have been set to $50, $700 and $400, respectively.\n4. Precision Pathway Evaluation\nTiming ~ 1.4s\n\nsummary(predicted)\n\n         Pathway Balanced Accuracy Total Cost Score\n1 clinical-miRNA              0.67       8400  4.50\n3       clinical              0.60       2100  4.50\n2   clinical-RNA              0.52      13800  3.00\n4          miRNA              0.50      16800  1.75\n5            RNA              0.50      29400  1.25\n\n\nGiven the costs provided earlier in calcCostsAndPerformance, this command outputs the summary of performance and cost of each potential pathway for evaluation. Based on the score rankings clinical data alone, and clinical data followed by miRNA data are tied for the best precision pathway. Clinical data followed by miRNA has the best balanced accuracy, but it is considerably more expensive than clinical data alone. RNA data is the most expensive and tied for the worst balanced accuracy.\n\nbubblePlot(predicted)\n\n\n\n\n\n\n\n\n\n\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale.\n\n\npng \n  2 \n\n\nThis bubble plot visualises the summary created above. In a situation with more potential pathways, it would allow greater ease in selecting the best pathway to optimise cost and performance. Here, the user can decide for themselves which aspect they place their priority on.\n\nplot(flowchart(predicted, \"clinical-miRNA\"))\n\n\n\n\n\n\n\n\nAttaching package: 'data.tree'\n\n\nThe following object is masked from 'package:Biobase':\n\n    Aggregate\n\n\nConsider clinical-miRNA as the pathway of greatest interest. This function creates a flowchart to show the stepwise process for determining melanoma prognosis. Clinical data is first used to classify patients into three prognosis groups: • Good prognosis: 40% of patients (17 out of total 42). • Uncertain prognosis: 43% of patients (18 out of 42) • Poor prognosis: 17% of patients (7 out of 42). Thus, clinical data alone classifies 57% of patients, while 43% requiring further assessment.\nFor the Uncertain prognosis group (18 patients), additional analysis using miRNA refines the classification: • Good prognosis: None are identified as “Good”. • Poor prognosis: 43 (18 patients) are classified as “Poor”. This is why a potential pathway incorporating clinical, mRNA, and miRNA data was not considered, as the first two datasets alone provided a prognosis outcome for all individuals.\n\nstrataPlot(predicted, \"clinical-miRNA\")\n\n\n\n\n\n\n\n\n\n\npng \n  2 \n\n\nThis function creates a plot which allow us to visualise where the prediction went wrong. Samples were mostly predicted correctly using clinical data. For the individuals who were assigned to use miRNA, the classifier tended to predict the “Poor” class most of the time for all samples and hence the small number of “Good” samples incorrectly had a dire prognosis, which is arguably better than giving patients with a truly poor prognosis a predicted good prognosis when they need the most intensive treatment.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Procedure 3: Multi-Platform Precision Pathway</span>"
    ]
  }
]